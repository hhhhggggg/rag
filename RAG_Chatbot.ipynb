{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Chatbot (Pinecone-only, OpenAI LLM)\n",
        "\n",
        "이 노트북은 웹 없이도 로컬에서 챗봇 동작을 확인할 수 있는 전용 런타임입니다.\n",
        "\n",
        "## ⚠️ 중요: 실행 전 필수 확인사항\n",
        "1. **커널 재시작**: `Ctrl+Shift+P` → \"Jupyter: Restart Kernel\" 실행\n",
        "2. **순차 실행**: Cell 1 → Cell 2 → Cell 3 → Cell 4 → Cell 5 순서대로 실행\n",
        "3. **중복 실행 금지**: Cell 5를 여러 번 실행하지 마세요 (while 루프가 중복 실행됨)\n",
        "\n",
        "실행 순서: 1) 환경/설치 → 2) Pinecone 연결 → 3) 검색 함수 → 4) LLM 챗봇"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
            "Platform: Windows-10-10.0.26100-SP0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# 환경/설치\n",
        "import sys, platform\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "\n",
        "!{sys.executable} -m pip install -q --upgrade pip\n",
        "!{sys.executable} -m pip install -q \"pinecone>=5.0.0\" sentence-transformers rank-bm25 pyyaml openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 1082}},\n",
            " 'total_vector_count': 1082,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "# Pinecone 연결\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "from config import PINECONE_API_KEY, PINECONE_INDEX_NAME\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(PINECONE_INDEX_NAME)\n",
        "print(index.describe_index_stats())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 검색 함수 (Cell 26 요약)\n",
        "import re, numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from config import EMBEDDING_MODEL_NAME\n",
        "\n",
        "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=\"cpu\")\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    return re.findall(r\"[A-Za-z0-9가-힣]+\", (s or \"\").lower())\n",
        "\n",
        "def vector_search(query: str, top_k: int = 50, meta_filter=None):\n",
        "    q_vec = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
        "    kwargs = {\"vector\": q_vec.tolist(), \"top_k\": top_k, \"include_values\": False, \"include_metadata\": True}\n",
        "    if meta_filter:\n",
        "        kwargs[\"filter\"] = meta_filter\n",
        "    res = index.query(**kwargs)\n",
        "    return [(m[\"id\"], float(m[\"score\"]), m.get(\"metadata\", {})) for m in res.get(\"matches\", [])]\n",
        "\n",
        "def bm25_over_candidates(query: str, candidates):\n",
        "    ids, docs = [], []\n",
        "    for cid, _, meta in candidates:\n",
        "        text = (meta or {}).get(\"text_content\") or \"\"\n",
        "        if not text:\n",
        "            title = (meta or {}).get(\"title\") or \"\"\n",
        "            keywords = (meta or {}).get(\"keywords\") or \"\"\n",
        "            text = f\"{title}\\n{keywords}\"\n",
        "        ids.append(cid)\n",
        "        docs.append(simple_tokenize(text))\n",
        "    if not docs:\n",
        "        return {}\n",
        "    bm25 = BM25Okapi(docs)\n",
        "    scores = bm25.get_scores(simple_tokenize(query)) if query else np.zeros(len(ids))\n",
        "    max_b = float(np.max(scores)) if len(scores) else 0.0\n",
        "    return {ids[i]: (float(scores[i])/max_b if max_b>0 else 0.0) for i in range(len(ids))}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 개선된 챗봇 준비 완료\n",
            "🤖 개선된 RAG 챗봇 (exit/quit/종료로 완전 종료)\n",
            "============================================================\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] z\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] z\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8182 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.8149 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 0.8008 | 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 0.8005 | 알로에바이오틱스 | alroebaiotigseu-chunk-12\n",
            "   5. 0.7980 | 이커머스 확장 스토리 상세 | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "   6. 0.7964 | 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   7. 0.7911 | 독자 개발 핵심 성분 | 3_3_4_proprietary_ingredients_univestin_uniwhite-chunk-2\n",
            "   8. 0.7882 | 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   9. 0.7869 | W389 더마 브라이트닝 선크림 | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "  10. 0.7867 | 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 알로에바이오틱스 | alroebaiotigseu-chunk-12\n",
            "   5. 이커머스 확장 스토리 상세 | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 102\n",
            "==========================================================================================\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8182 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.8149 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 0.8008 | 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 0.8005 | 알로에바이오틱스 | alroebaiotigseu-chunk-12\n",
            "   5. 0.7980 | 이커머스 확장 스토리 상세 | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "   6. 0.7964 | 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   7. 0.7911 | 독자 개발 핵심 성분 | 3_3_4_proprietary_ingredients_univestin_uniwhite-chunk-2\n",
            "   8. 0.7882 | 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   9. 0.7869 | W389 더마 브라이트닝 선크림 | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "  10. 0.7867 | 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 알로에바이오틱스 | alroebaiotigseu-chunk-12\n",
            "   5. 이커머스 확장 스토리 상세 | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 102\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "질문 \"z\"에 대한 답변을 제공할 수 없습니다. 제공된 컨텍스트는 질문에 대한 정보가 부족합니다.\n",
            "\n",
            "출처:\n",
            "- [#1] 홍삼액골드\n",
            "- [#2] CAP 프로젝트 상세 (1기~5기 성과)\n",
            "- [#3] 윤리경영 및 UNGC 참여\n",
            "- [#4] 알로에바이오틱스\n",
            "- [#5] 이커머스 확장 스토리 상세\n",
            "------------------------------------------------------------\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "질문 \"z\"에 대한 답변을 제공할 수 없습니다. 제공된 컨텍스트는 질문에 대한 정보가 부족합니다.\n",
            "\n",
            "출처:\n",
            "- [#1] 홍삼액골드\n",
            "- [#2] CAP 프로젝트 상세 (1기~5기 성과)\n",
            "- [#3] 윤리경영 및 UNGC 참여\n",
            "- [#4] 알로에바이오틱스\n",
            "- [#5] 이커머스 확장 스토리 상세\n",
            "------------------------------------------------------------\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] ezit\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] ezit\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.7876 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.7843 | 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 0.7799 | 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 0.7789 | 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "   5. 0.7743 | 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   6. 0.7732 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   7. 0.7695 | 2010년대: 지속가능경영 강화 및 글로벌 인증 확대 | 2_2_5_2010s_sustainability_and_global_certification-chunk-2\n",
            "   8. 0.7691 | 중국 하이난 농장 | 3_2_5_china_hainan_farm-chunk-1\n",
            "   9. 0.7675 | 유니베라 유산균 플러스 | yusangyunpeulreoseu-chunk-5\n",
            "  10. 0.7671 | 에이지엑스 | eijiegseu-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "   5. 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 161\n",
            "==========================================================================================\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.7876 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.7843 | 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 0.7799 | 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 0.7789 | 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "   5. 0.7743 | 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   6. 0.7732 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   7. 0.7695 | 2010년대: 지속가능경영 강화 및 글로벌 인증 확대 | 2_2_5_2010s_sustainability_and_global_certification-chunk-2\n",
            "   8. 0.7691 | 중국 하이난 농장 | 3_2_5_china_hainan_farm-chunk-1\n",
            "   9. 0.7675 | 유니베라 유산균 플러스 | yusangyunpeulreoseu-chunk-5\n",
            "  10. 0.7671 | 에이지엑스 | eijiegseu-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 주요 브랜드 아이덴티티 | 4_3_brand_identity-chunk-1\n",
            "   5. 윤리경영 및 UNGC 참여 | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 161\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "\"ezit\"에 대한 구체적인 정보는 제공된 컨텍스트에서 찾을 수 없습니다. \n",
            "\n",
            "출처:\n",
            "- [#3] 공된 파일에서 해당 제품에 대한 정보를 찾을 수 없습니다.\n",
            "------------------------------------------------------------\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "\"ezit\"에 대한 구체적인 정보는 제공된 컨텍스트에서 찾을 수 없습니다. \n",
            "\n",
            "출처:\n",
            "- [#3] 공된 파일에서 해당 제품에 대한 정보를 찾을 수 없습니다.\n",
            "------------------------------------------------------------\n",
            "👋 종료합니다.\n",
            "\n",
            "✨ 챗봇이 완전히 종료되었습니다.\n",
            "👋 종료합니다.\n",
            "\n",
            "✨ 챗봇이 완전히 종료되었습니다.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# 개선된 LLM 챗봇\n",
        "from collections import deque\n",
        "from typing import List, Dict, Tuple\n",
        "from openai import OpenAI\n",
        "from config import OPENAI_API_KEY, LLM_MODEL_NAME, DEFAULT_VECTOR_WEIGHT, DEFAULT_BM25_WEIGHT, DEFAULT_TOP_K, DEFAULT_CONTEXT_CHARS, DEFAULT_CONTEXT_TOP_N\n",
        "import os\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 개선된 시스템 프롬프트\n",
        "SYSTEM_PROMPT = (\n",
        "    \"너는 RAG 기반 도우미야. 제공된 컨텍스트를 우선 활용해서 간결하고 정확하게 답해.\\n\"\n",
        "    \"근거가 없으면 솔직히 모른다고 말해.\\n\"\n",
        "    \"출처를 bullet로 함께 제공해.\"\n",
        "    )\n",
        "\n",
        "def build_context_improved(query: str, candidates: List[Tuple[str, float, Dict]], vec_w: float, bm25_w: float, top_n: int, max_chars: int):\n",
        "    \"\"\"개선된 컨텍스트 빌딩\"\"\"\n",
        "    bm25_scores = bm25_over_candidates(query, candidates)\n",
        "    scored = []\n",
        "    for cid, v_score, meta in candidates:\n",
        "        b_score = bm25_scores.get(cid, 0.0)\n",
        "        combo = vec_w * float(v_score) + bm25_w * float(b_score)\n",
        "        scored.append((combo, cid, meta))\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    picked, used = [], 0\n",
        "    for _, cid, meta in scored[: max(1, int(top_n) * 3)]:\n",
        "        text = (meta or {}).get(\"text_content\") or (meta or {}).get(\"title\") or \"\"\n",
        "        if not text:\n",
        "            continue\n",
        "        if used + len(text) > max_chars:\n",
        "            continue\n",
        "        picked.append({\n",
        "            \"id\": cid,\n",
        "            \"title\": (meta or {}).get(\"title\"),\n",
        "            \"source\": (meta or {}).get(\"source_doc\"),\n",
        "            \"chunk\": text,\n",
        "        })\n",
        "        used += len(text)\n",
        "        if len(picked) >= int(top_n):\n",
        "            break\n",
        "    return picked\n",
        "\n",
        "def call_openai_improved(api_key: str, model: str, messages: List[Dict]) -> str:\n",
        "    \"\"\"개선된 OpenAI 호출\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI API 키가 필요합니다.\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    r = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return r.choices[0].message.content or \"\"\n",
        "\n",
        "_history_deque = deque(maxlen=3)\n",
        "\n",
        "def build_messages_with_history(question: str, context_text: str, citations: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"최근 대화 몇 턴을 포함하도록 메시지를 구성\"\"\"\n",
        "    messages: List[Dict[str, str]] = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    for past_question, past_answer, _ in _history_deque:\n",
        "        if past_question:\n",
        "            messages.append({\"role\": \"user\", \"content\": past_question})\n",
        "        if past_answer:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": past_answer})\n",
        "    user_content = (\n",
        "        f\"질문: {question}\\n\\n컨텍스트:\\n{context_text}\\n\\n\"\n",
        "        \"컨텍스트를 기반으로 답하세요. 답 끝에 '출처' 섹션을 넣어 아래 목록에서 근거를 인용하세요.\\n\"\n",
        "        f\"출처 목록:\\n{citations}\"\n",
        "    )\n",
        "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "    return messages\n",
        "\n",
        "def chat_once_improved(question: str, vec_w=DEFAULT_VECTOR_WEIGHT, bm25_w=DEFAULT_BM25_WEIGHT, top_k=DEFAULT_TOP_K, ctx_n=DEFAULT_CONTEXT_TOP_N, max_ctx_chars=DEFAULT_CONTEXT_CHARS, debug=True):\n",
        "    \"\"\"개선된 챗봇 로직\"\"\"\n",
        "    if debug:\n",
        "        print(\"=\"*90)\n",
        "        print(f\"[질문] {question}\")\n",
        "\n",
        "    # 벡터 검색\n",
        "    candidates = vector_search(question, top_k=top_k)\n",
        "    \n",
        "    if debug:\n",
        "        print(f\"[벡터 후보 수] {len(candidates)}\")\n",
        "        print(\"-\"*90)\n",
        "        print(\"[Vector Top 10]\")\n",
        "        for i, (cid, vscore, meta) in enumerate(candidates[:10], 1):\n",
        "            print(f\"  {i:>2}. {vscore:.4f} | {(meta or {}).get('title','N/A')} | {cid}\")\n",
        "\n",
        "    # 개선된 컨텍스트 빌딩\n",
        "    contexts = build_context_improved(question, candidates, vec_w, bm25_w, ctx_n, max_ctx_chars)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[선택된 컨텍스트 수] {len(contexts)}\")\n",
        "        for i, ctx in enumerate(contexts, 1):\n",
        "            print(f\"  {i:>2}. {ctx['title'] or 'N/A'} | {ctx['id']}\")\n",
        "\n",
        "    # 컨텍스트 텍스트 구성\n",
        "    context_text = \"\\n\\n\".join([f\"[#{i+1}] {c['chunk']}\" for i, c in enumerate(contexts)])\n",
        "    citations = \"\\n\".join(\n",
        "        [f\"- [#{i+1}] {c.get('title') or c.get('source') or c['id']}\" for i, c in enumerate(contexts)]\n",
        "    )\n",
        "\n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[컨텍스트 길이] {len(context_text)}\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "    # LLM 호출\n",
        "    messages = build_messages_with_history(question, context_text, citations)\n",
        "\n",
        "    answer = call_openai_improved(\n",
        "        OPENAI_API_KEY,\n",
        "        LLM_MODEL_NAME,\n",
        "        messages,\n",
        "    )\n",
        "\n",
        "    # 히스토리 저장\n",
        "    _history_deque.append((question, answer, \"\"))\n",
        "    \n",
        "    return answer.strip()\n",
        "\n",
        "# ========================================\n",
        "# 중복 실행 방지 체크\n",
        "# ========================================\n",
        "_CHATBOT_PID_FILE = \".chatbot_running.pid\"\n",
        "\n",
        "if os.path.exists(_CHATBOT_PID_FILE):\n",
        "    print(\"⚠️  경고: 챗봇이 이미 실행 중일 수 있습니다!\")\n",
        "    print(\"⚠️  다른 커널에서 실행 중이거나 이전 실행이 완전히 종료되지 않았습니다.\")\n",
        "    print(\"⚠️  해결 방법:\")\n",
        "    print(\"   1. Ctrl+Shift+P → 'Jupyter: Restart Kernel' 실행\")\n",
        "    print(\"   2. 모든 셀을 순차적으로 다시 실행 (1→2→3→4→5)\")\n",
        "    raise RuntimeError(\"중복 실행 방지: 커널을 재시작하세요\")\n",
        "\n",
        "# PID 파일 생성\n",
        "with open(_CHATBOT_PID_FILE, \"w\") as f:\n",
        "    f.write(str(os.getpid()))\n",
        "\n",
        "print(\"✅ 개선된 챗봇 준비 완료\")\n",
        "print(\"🤖 개선된 RAG 챗봇 (exit/quit/종료로 완전 종료)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    _running = True\n",
        "    while _running:\n",
        "        try:\n",
        "            q = input(\"\\n❓ 질문: \").strip()\n",
        "        except (EOFError, KeyboardInterrupt):\n",
        "            print(\"\\n👋 종료합니다.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if q.lower() in [\"exit\",\"quit\",\"종료\"]:\n",
        "            print(\"👋 종료합니다.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if not q:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(\"\\n처리 중...⏳\")\n",
        "            out = chat_once_improved(\n",
        "                q, \n",
        "                vec_w=DEFAULT_VECTOR_WEIGHT, \n",
        "                bm25_w=DEFAULT_BM25_WEIGHT, \n",
        "                top_k=DEFAULT_TOP_K, \n",
        "                ctx_n=DEFAULT_CONTEXT_TOP_N, \n",
        "                max_ctx_chars=DEFAULT_CONTEXT_CHARS,\n",
        "                debug=True\n",
        "            )\n",
        "            print(\"\\n💬 답변:\")\n",
        "            print(\"-\"*60)\n",
        "            print(out)\n",
        "            print(\"-\"*60)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            # 오류가 나도 루프는 계속\n",
        "finally:\n",
        "    # PID 파일 삭제\n",
        "    if os.path.exists(_CHATBOT_PID_FILE):\n",
        "        os.remove(_CHATBOT_PID_FILE)\n",
        "    print(\"\\n✨ 챗봇이 완전히 종료되었습니다.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
