{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Chatbot (Pinecone-only, OpenAI LLM)\n",
        "\n",
        "이 노트북은 웹 없이도 로컬에서 챗봇 동작을 확인할 수 있는 전용 런타임입니다.\n",
        "\n",
        "## ⚠️ 중요: 실행 전 필수 확인사항\n",
        "1. **커널 재시작**: `Ctrl+Shift+P` → \"Jupyter: Restart Kernel\" 실행\n",
        "2. **순차 실행**: Cell 1 → Cell 2 → Cell 3 → Cell 4 → Cell 5 순서대로 실행\n",
        "3. **중복 실행 금지**: Cell 5를 여러 번 실행하지 마세요 (while 루프가 중복 실행됨)\n",
        "\n",
        "실행 순서: 1) 환경/설치 → 2) Pinecone 연결 → 3) 검색 함수 → 4) LLM 챗봇"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
            "Platform: Windows-10-10.0.26100-SP0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# 환경/설치\n",
        "import sys, platform\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "\n",
        "!{sys.executable} -m pip install -q --upgrade pip\n",
        "!{sys.executable} -m pip install -q \"pinecone>=5.0.0\" sentence-transformers rank-bm25 pyyaml openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 1082}},\n",
            " 'total_vector_count': 1082,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "# Pinecone 연결\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "from config import PINECONE_API_KEY, PINECONE_INDEX_NAME\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(PINECONE_INDEX_NAME)\n",
        "print(index.describe_index_stats())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 검색 함수 (Cell 26 요약)\n",
        "import re, numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from config import EMBEDDING_MODEL_NAME\n",
        "\n",
        "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=\"cpu\")\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    return re.findall(r\"[A-Za-z0-9가-힣]+\", (s or \"\").lower())\n",
        "\n",
        "def vector_search(query: str, top_k: int = 50, meta_filter=None):\n",
        "    q_vec = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
        "    kwargs = {\"vector\": q_vec.tolist(), \"top_k\": top_k, \"include_values\": False, \"include_metadata\": True}\n",
        "    if meta_filter:\n",
        "        kwargs[\"filter\"] = meta_filter\n",
        "    res = index.query(**kwargs)\n",
        "    return [(m[\"id\"], float(m[\"score\"]), m.get(\"metadata\", {})) for m in res.get(\"matches\", [])]\n",
        "\n",
        "def bm25_over_candidates(query: str, candidates):\n",
        "    ids, docs = [], []\n",
        "    for cid, _, meta in candidates:\n",
        "        text = (meta or {}).get(\"text_content\") or \"\"\n",
        "        if not text:\n",
        "            title = (meta or {}).get(\"title\") or \"\"\n",
        "            keywords = (meta or {}).get(\"keywords\") or \"\"\n",
        "            text = f\"{title}\\n{keywords}\"\n",
        "        ids.append(cid)\n",
        "        docs.append(simple_tokenize(text))\n",
        "    if not docs:\n",
        "        return {}\n",
        "    bm25 = BM25Okapi(docs)\n",
        "    scores = bm25.get_scores(simple_tokenize(query)) if query else np.zeros(len(ids))\n",
        "    max_b = float(np.max(scores)) if len(scores) else 0.0\n",
        "    return {ids[i]: (float(scores[i])/max_b if max_b>0 else 0.0) for i in range(len(ids))}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 개선된 챗봇 준비 완료\n",
            "🤖 개선된 RAG 챗봇 (exit/quit/종료로 완전 종료)\n",
            "============================================================\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] 유니베라 창립=년도\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8554 | 연도별 역사 정리 | 2_2_history_by_year-chunk-0\n",
            "   2. 0.8550 | 전체 역사 종합 | 2_1_overall_history-chunk-0\n",
            "   3. 0.8541 | 1970년대: 창업과 도전 | 2_2_1_1970s_founding_and_challenges-chunk-0\n",
            "   4. 0.8514 | 1970년대: 창업과 도전 | 2-2-1-1970s-founding-and-challenges-chunk-0\n",
            "   5. 0.8469 | 기업 역사 (Corporate History) | 2-corporate-history-chunk-0\n",
            "   6. 0.8465 | 기업 역사 (Corporate History) | 2_corporate_history-chunk-0\n",
            "   7. 0.8458 | 2000년대: 웰니스 기업으로의 도약 | 2-2-4-2000s-wellness-leap-chunk-0\n",
            "   8. 0.8451 | 국내 사업 확장 히스토리 상세 | 2-3-domestic-business-expansion-history-chunk-0\n",
            "   9. 0.8448 | 1980년대: 글로벌 진출 | 2_2_2_1980s_global_expansion-chunk-0\n",
            "  10. 0.8441 | 전체 역사 종합 | 2-1-overall-history-chunk-0\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 연도별 역사 정리 | 2_2_history_by_year-chunk-0\n",
            "   2. 브랜드 확장 스토리 상세 | 2_6_brand_expansion_story_detail-chunk-0\n",
            "   3. 2000년대: 웰니스 기업으로의 도약 | 2_2_4_2000s_wellness_leap-chunk-1\n",
            "   4. 2000년대: 웰니스 기업으로의 도약 | 2_2_4_2000s_wellness_leap-chunk-0\n",
            "   5. 국내 사업 확장 히스토리 상세 | 2_3_domestic_business_expansion_history-chunk-0\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 2450\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "유니베라는 1976년에 창립되었습니다. \n",
            "\n",
            "출처:\n",
            "- [#1] 연도별 역사 정리\n",
            "- [#5] 국내 사업 확장 히스토리 상세\n",
            "------------------------------------------------------------\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] 근거가 뭐야\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8031 | CAP 프로젝트 상세 (1기~5기 성과) | 3-3-1-cap-project-detail-phases1to5-chunk-1\n",
            "   2. 0.8021 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   3. 0.7970 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   4. 0.7934 | 창업자 배경과 철학 | 1-2-founder-background-and-philosophy-front\n",
            "   5. 0.7934 | 창업자 배경과 철학 | 1_2_founder_background_and_philosophy-front\n",
            "   6. 0.7930 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-2\n",
            "   7. 0.7920 | 연구개발 히스토리 상세 | 2-5-rnd-history-detail-chunk-0\n",
            "   8. 0.7919 | 슈퍼겔맥스 | syupeogelmaegseu-chunk-13\n",
            "   9. 0.7909 | W389 더마 브라이트닝 선크림 | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "  10. 0.7894 | 생산 (Production): 네이처텍 (Naturetech) | 3_4_production_subsidiary_naturetech-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. CAP 프로젝트 상세 (1기~5기 성과) | 3-3-1-cap-project-detail-phases1to5-chunk-1\n",
            "   2. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   3. CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   4. 창업자 배경과 철학 | 1-2-founder-background-and-philosophy-front\n",
            "   5. 창업자 배경과 철학 | 1_2_founder_background_and_philosophy-front\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 375\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "유니베라는 1976년에 창립되었습니다. \n",
            "\n",
            "출처:\n",
            "- [#4] 창업자 배경과 철학\n",
            "- [#5] 창업자 배경과 철학\n",
            "------------------------------------------------------------\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] 어떻게 알아\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8267 | 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.8058 | W389 더마 브라이트닝 선크림 | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "   3. 0.7978 | 노회비책 | nohoebicaeg-chunk-3\n",
            "   4. 0.7975 | 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   5. 0.7944 | 파이토클린샷 | doc-chunk-6\n",
            "   6. 0.7941 | 알로엔 더골드 플루이드 | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   7. 0.7940 | 베라힐 토탈케어 치약 | berahil_totalkeeo_ciyag-chunk-3\n",
            "   8. 0.7930 | CAP 프로젝트 상세 (1기~5기 성과) | 3-3-1-cap-project-detail-phases1to5-chunk-1\n",
            "   9. 0.7928 | 알로에바이오틱스 | alroebaiotigseu-chunk-12\n",
            "  10. 0.7913 | CAP 프로젝트 상세 (1기~5기 성과) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 홍삼액골드 | hongsamaeggoldeu-chunk-4\n",
            "   2. W389 더마 브라이트닝 선크림 | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "   3. 노회비책 | nohoebicaeg-chunk-3\n",
            "   4. 알로엔 리바이탈 모델링 팩 | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   5. 파이토클린샷 | doc-chunk-6\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 290\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "제공된 컨텍스트에는 유니베라 창립 연도에 대한 정보가 포함되어 있지 않습니다. 따라서 정확한 정보를 제공할 수 없습니다.\n",
            "\n",
            "출처:\n",
            "- [#4] 공된 파일에서 해당 제품에 대한 정보를 찾을 수 없습니다.\n",
            "------------------------------------------------------------\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] 피부가 너무 땡겨\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8359 | 알로엔 더 블루 미스트 | alroen_deo_beulru_miseuteu-chunk-1\n",
            "   2. 0.8343 | 알로엔 더블루 기초 | alroen_deobeulru_gico-chunk-3\n",
            "   3. 0.8328 | 알로엔 더 골드 안티에이징 (플루이드, 앰플, 아이크림, 크림) | alroen_deogoldeu_antieijing_peulruideu_aempeul_aikeurim_keurim-chunk-1\n",
            "   4. 0.8324 | 알로엔 디오리진 스킨케어 100 | alroen_diorijin_seukinkeeo100-chunk-9\n",
            "   5. 0.8306 | 알로엔 모이스처 캡슐젤 | alroen_moiseuceo_kaebsyuljel-chunk-1\n",
            "   6. 0.8304 | 알로엔 더블루 딥 클렌징 폼 | alroen_deobeulru_dibkeulrenjing_pom-chunk-4\n",
            "   7. 0.8303 | 알로엔 더블루 모이스처 로션 | alroen_deobeulru_moiseuceo_rosyeon-chunk-11\n",
            "   8. 0.8302 | 베라힐 내추럴 마일드 바디로션 | berahil_naecureol_maildeu_badirosyeon-chunk-8\n",
            "   9. 0.8289 | 알로엔 디오리진 SOS 크림 | alroen_diorijin_soskeurim-chunk-5\n",
            "  10. 0.8286 | W389 더마 브라이트닝 필링젤 | w389_deoma_beuraiteuning_pilringjel-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 알로엔 톤업 크림 | alroen_toneobkeurim-chunk-3\n",
            "   2. 알로엔 더블루 모이스처 크림 | alroen_deobeulru_moiseuceo_keurim-chunk-6\n",
            "   3. 알로엔 모이스처 캡슐젤 | alroen_moiseuceo_kaebsyuljel-chunk-1\n",
            "   4. 알로엔 디오리진 스킨케어 100 | alroen_diorijin_seukinkeeo100-chunk-7\n",
            "   5. 알로엔 디오리진 수딩스틱 | alroen_diorijin_sudingseutig-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 1839\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "피부가 너무 땡기는 경우, 충분한 수분 공급이 중요합니다. 극건성 피부의 경우 고농축 크림 사용 전에 수분을 충분히 공급하는 것이 필요합니다. 또한, 피부 장벽이 손상되면 건조함이 심해질 수 있으므로, 피부 진정과 장벽 강화를 위한 제품 사용을 고려해보세요. '알로엔 모이스처 캡슐젤'이나 '알로엔 디오리진 스킨케어 100' 제품이 일반적인 보습 및 진정에 효과적입니다.\n",
            "\n",
            "출처:\n",
            "- [#2] 알로엔 더블루 모이스처 크림\n",
            "- [#3] 알로엔 모이스처 캡슐젤\n",
            "- [#4] 알로엔 디오리진 스킨케어 100\n",
            "------------------------------------------------------------\n",
            "\n",
            "처리 중...⏳\n",
            "==========================================================================================\n",
            "[질문] 성분이 뭔데\n",
            "[벡터 후보 수] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8312 | 알키드 징크 | alkideu_jingkeu-chunk-0\n",
            "   2. 0.8281 | 파이토클린샷 | doc-chunk-6\n",
            "   3. 0.8261 | 독자 개발 핵심 성분 | 3_3_4_proprietary_ingredients_univestin_uniwhite-chunk-2\n",
            "   4. 0.8227 | 독자 개발 핵심 성분 | 3_3_4_proprietary_ingredients_univestin_uniwhite-front\n",
            "   5. 0.8226 | 독자 개발 핵심 성분 | 3-3-4-proprietary-ingredients-univestin-uniwhite-front\n",
            "   6. 0.8181 | 알로에 테라샷 | alroeterasyas-chunk-12\n",
            "   7. 0.8174 | 빌리브 웰니스 푸드S | s-chunk-0\n",
            "   8. 0.8146 | 파이토클린샷 | paitokeulrinsyas-chunk-13\n",
            "   9. 0.8137 | 빌리브 효소 | bilribeuhyoso-chunk-3\n",
            "  10. 0.8135 | 알로엔 립세럼 스틱 | alroen_rib_sereom_seutig-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[선택된 컨텍스트 수] 5\n",
            "   1. 러시아 크라스키노 농장 | 3_2_4_russia_kraskino_farm-chunk-0\n",
            "   2. 알로엔 더블루 모이스처 토너 | alroen_deobeulru_moiseuceo_toneo-chunk-2\n",
            "   3. 레벨지 플러스 | rebeljipeulreoseu-chunk-3\n",
            "   4. New 알로에버 플러스 | alroebeopeulreoseu-chunk-1\n",
            "   5. 알로엔 더골드 앰플 | alroen_deogoldeu_aempeul-chunk-0\n",
            "------------------------------------------------------------------------------------------\n",
            "[컨텍스트 길이] 2533\n",
            "==========================================================================================\n",
            "\n",
            "💬 답변:\n",
            "------------------------------------------------------------\n",
            "피부 제품에 포함된 주요 성분은 다음과 같습니다:\n",
            "\n",
            "1. **알로엠 콤플렉스**: 베이비 알로에, 7중 히알루론산, 프리미엄 온천수로 구성되어 피부 수분을 유지하고 아쿠아포린을 활성화합니다.\n",
            "2. **베이비 알로에**: 수분 유지, 항산화, 항알러지 효능이 있습니다.\n",
            "3. **7중 히알루론산**: 다양한 분자량으로 피부에 맞춤형 수분 공급을 합니다.\n",
            "4. **프리미엄 온천수**: 미네랄이 풍부하여 피부를 진정시키고 보습합니다.\n",
            "5. **알지랄렌**: 주름 생성을 억제하고 콜라겐 생성을 촉진합니다.\n",
            "\n",
            "출처:\n",
            "- [#2] 알로엔 더블루 모이스처 토너\n",
            "- [#5] 알로엔 더골드 앰플\n",
            "------------------------------------------------------------\n",
            "👋 종료합니다.\n",
            "\n",
            "✨ 챗봇이 완전히 종료되었습니다.\n"
          ]
        }
      ],
      "source": [
        "# 개선된 LLM 챗봇\n",
        "from collections import deque\n",
        "from typing import List, Dict, Tuple\n",
        "from openai import OpenAI\n",
        "from config import OPENAI_API_KEY, LLM_MODEL_NAME, DEFAULT_VECTOR_WEIGHT, DEFAULT_BM25_WEIGHT, DEFAULT_TOP_K, DEFAULT_CONTEXT_CHARS, DEFAULT_CONTEXT_TOP_N\n",
        "import os\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 개선된 시스템 프롬프트\n",
        "SYSTEM_PROMPT = (\n",
        "    \"너는 RAG 기반 도우미야. 제공된 컨텍스트를 우선 활용해서 간결하고 정확하게 답해.\\n\"\n",
        "    \"근거가 없으면 솔직히 모른다고 말해.\\n\"\n",
        "    \"출처를 bullet로 함께 제공해.\"\n",
        "    )\n",
        "\n",
        "def build_context_improved(query: str, candidates: List[Tuple[str, float, Dict]], vec_w: float, bm25_w: float, top_n: int, max_chars: int):\n",
        "    \"\"\"개선된 컨텍스트 빌딩\"\"\"\n",
        "    bm25_scores = bm25_over_candidates(query, candidates)\n",
        "    scored = []\n",
        "    for cid, v_score, meta in candidates:\n",
        "        b_score = bm25_scores.get(cid, 0.0)\n",
        "        combo = vec_w * float(v_score) + bm25_w * float(b_score)\n",
        "        scored.append((combo, cid, meta))\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    picked, used = [], 0\n",
        "    for _, cid, meta in scored[: max(1, int(top_n) * 3)]:\n",
        "        text = (meta or {}).get(\"text_content\") or (meta or {}).get(\"title\") or \"\"\n",
        "        if not text:\n",
        "            continue\n",
        "        if used + len(text) > max_chars:\n",
        "            continue\n",
        "        picked.append({\n",
        "            \"id\": cid,\n",
        "            \"title\": (meta or {}).get(\"title\"),\n",
        "            \"source\": (meta or {}).get(\"source_doc\"),\n",
        "            \"chunk\": text,\n",
        "        })\n",
        "        used += len(text)\n",
        "        if len(picked) >= int(top_n):\n",
        "            break\n",
        "    return picked\n",
        "\n",
        "def call_openai_improved(api_key: str, model: str, messages: List[Dict]) -> str:\n",
        "    \"\"\"개선된 OpenAI 호출\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI API 키가 필요합니다.\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    r = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return r.choices[0].message.content or \"\"\n",
        "\n",
        "_history_deque = deque(maxlen=3)\n",
        "\n",
        "def build_messages_with_history(question: str, context_text: str, citations: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"최근 대화 몇 턴을 포함하도록 메시지를 구성\"\"\"\n",
        "    messages: List[Dict[str, str]] = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    for past_question, past_answer, _ in _history_deque:\n",
        "        if past_question:\n",
        "            messages.append({\"role\": \"user\", \"content\": past_question})\n",
        "        if past_answer:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": past_answer})\n",
        "    user_content = (\n",
        "        f\"질문: {question}\\n\\n컨텍스트:\\n{context_text}\\n\\n\"\n",
        "        \"컨텍스트를 기반으로 답하세요. 답 끝에 '출처' 섹션을 넣어 아래 목록에서 근거를 인용하세요.\\n\"\n",
        "        f\"출처 목록:\\n{citations}\"\n",
        "    )\n",
        "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "    return messages\n",
        "\n",
        "def chat_once_improved(question: str, vec_w=DEFAULT_VECTOR_WEIGHT, bm25_w=DEFAULT_BM25_WEIGHT, top_k=DEFAULT_TOP_K, ctx_n=DEFAULT_CONTEXT_TOP_N, max_ctx_chars=DEFAULT_CONTEXT_CHARS, debug=True):\n",
        "    \"\"\"개선된 챗봇 로직\"\"\"\n",
        "    if debug:\n",
        "        print(\"=\"*90)\n",
        "        print(f\"[질문] {question}\")\n",
        "\n",
        "    # 벡터 검색\n",
        "    candidates = vector_search(question, top_k=top_k)\n",
        "    \n",
        "    if debug:\n",
        "        print(f\"[벡터 후보 수] {len(candidates)}\")\n",
        "        print(\"-\"*90)\n",
        "        print(\"[Vector Top 10]\")\n",
        "        for i, (cid, vscore, meta) in enumerate(candidates[:10], 1):\n",
        "            print(f\"  {i:>2}. {vscore:.4f} | {(meta or {}).get('title','N/A')} | {cid}\")\n",
        "\n",
        "    # 개선된 컨텍스트 빌딩\n",
        "    contexts = build_context_improved(question, candidates, vec_w, bm25_w, ctx_n, max_ctx_chars)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[선택된 컨텍스트 수] {len(contexts)}\")\n",
        "        for i, ctx in enumerate(contexts, 1):\n",
        "            print(f\"  {i:>2}. {ctx['title'] or 'N/A'} | {ctx['id']}\")\n",
        "\n",
        "    # 컨텍스트 텍스트 구성\n",
        "    context_text = \"\\n\\n\".join([f\"[#{i+1}] {c['chunk']}\" for i, c in enumerate(contexts)])\n",
        "    citations = \"\\n\".join(\n",
        "        [f\"- [#{i+1}] {c.get('title') or c.get('source') or c['id']}\" for i, c in enumerate(contexts)]\n",
        "    )\n",
        "\n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[컨텍스트 길이] {len(context_text)}\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "    # LLM 호출\n",
        "    messages = build_messages_with_history(question, context_text, citations)\n",
        "\n",
        "    answer = call_openai_improved(\n",
        "        OPENAI_API_KEY,\n",
        "        LLM_MODEL_NAME,\n",
        "        messages,\n",
        "    )\n",
        "\n",
        "    # 히스토리 저장\n",
        "    _history_deque.append((question, answer, \"\"))\n",
        "    \n",
        "    return answer.strip()\n",
        "\n",
        "# ========================================\n",
        "# 중복 실행 방지 체크\n",
        "# ========================================\n",
        "_CHATBOT_PID_FILE = \".chatbot_running.pid\"\n",
        "\n",
        "if os.path.exists(_CHATBOT_PID_FILE):\n",
        "    print(\"⚠️  경고: 챗봇이 이미 실행 중일 수 있습니다!\")\n",
        "    print(\"⚠️  다른 커널에서 실행 중이거나 이전 실행이 완전히 종료되지 않았습니다.\")\n",
        "    print(\"⚠️  해결 방법:\")\n",
        "    print(\"   1. Ctrl+Shift+P → 'Jupyter: Restart Kernel' 실행\")\n",
        "    print(\"   2. 모든 셀을 순차적으로 다시 실행 (1→2→3→4→5)\")\n",
        "    raise RuntimeError(\"중복 실행 방지: 커널을 재시작하세요\")\n",
        "\n",
        "# PID 파일 생성\n",
        "with open(_CHATBOT_PID_FILE, \"w\") as f:\n",
        "    f.write(str(os.getpid()))\n",
        "\n",
        "print(\"✅ 개선된 챗봇 준비 완료\")\n",
        "print(\"🤖 개선된 RAG 챗봇 (exit/quit/종료로 완전 종료)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    _running = True\n",
        "    while _running:\n",
        "        try:\n",
        "            q = input(\"\\n❓ 질문: \").strip()\n",
        "        except (EOFError, KeyboardInterrupt):\n",
        "            print(\"\\n👋 종료합니다.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if q.lower() in [\"exit\",\"quit\",\"종료\"]:\n",
        "            print(\"👋 종료합니다.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if not q:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(\"\\n처리 중...⏳\")\n",
        "            out = chat_once_improved(\n",
        "                q, \n",
        "                vec_w=DEFAULT_VECTOR_WEIGHT, \n",
        "                bm25_w=DEFAULT_BM25_WEIGHT, \n",
        "                top_k=DEFAULT_TOP_K, \n",
        "                ctx_n=DEFAULT_CONTEXT_TOP_N, \n",
        "                max_ctx_chars=DEFAULT_CONTEXT_CHARS,\n",
        "                debug=True\n",
        "            )\n",
        "            print(\"\\n💬 답변:\")\n",
        "            print(\"-\"*60)\n",
        "            print(out)\n",
        "            print(\"-\"*60)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류: {e}\")\n",
        "            # 오류가 나도 루프는 계속\n",
        "finally:\n",
        "    # PID 파일 삭제\n",
        "    if os.path.exists(_CHATBOT_PID_FILE):\n",
        "        os.remove(_CHATBOT_PID_FILE)\n",
        "    print(\"\\n✨ 챗봇이 완전히 종료되었습니다.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
