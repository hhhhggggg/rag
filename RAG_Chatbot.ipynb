{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Chatbot (Pinecone-only, OpenAI LLM)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ ì›¹ ì—†ì´ë„ ë¡œì»¬ì—ì„œ ì±—ë´‡ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì „ìš© ëŸ°íƒ€ì„ì…ë‹ˆë‹¤.\n",
        "\n",
        "## âš ï¸ ì¤‘ìš”: ì‹¤í–‰ ì „ í•„ìˆ˜ í™•ì¸ì‚¬í•­\n",
        "1. **ì»¤ë„ ì¬ì‹œì‘**: `Ctrl+Shift+P` â†’ \"Jupyter: Restart Kernel\" ì‹¤í–‰\n",
        "2. **ìˆœì°¨ ì‹¤í–‰**: Cell 1 â†’ Cell 2 â†’ Cell 3 â†’ Cell 4 â†’ Cell 5 ìˆœì„œëŒ€ë¡œ ì‹¤í–‰\n",
        "3. **ì¤‘ë³µ ì‹¤í–‰ ê¸ˆì§€**: Cell 5ë¥¼ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš” (while ë£¨í”„ê°€ ì¤‘ë³µ ì‹¤í–‰ë¨)\n",
        "\n",
        "ì‹¤í–‰ ìˆœì„œ: 1) í™˜ê²½/ì„¤ì¹˜ â†’ 2) Pinecone ì—°ê²° â†’ 3) ê²€ìƒ‰ í•¨ìˆ˜ â†’ 4) LLM ì±—ë´‡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
            "Platform: Windows-10-10.0.26100-SP0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "# í™˜ê²½/ì„¤ì¹˜\n",
        "import sys, platform\n",
        "print('Python:', sys.version)\n",
        "print('Platform:', platform.platform())\n",
        "\n",
        "!{sys.executable} -m pip install -q --upgrade pip\n",
        "!{sys.executable} -m pip install -q \"pinecone>=5.0.0\" sentence-transformers rank-bm25 pyyaml openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'dimension': 1024,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'': {'vector_count': 1082}},\n",
            " 'total_vector_count': 1082,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "# Pinecone ì—°ê²°\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "from config import PINECONE_API_KEY, PINECONE_INDEX_NAME\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index = pc.Index(PINECONE_INDEX_NAME)\n",
        "print(index.describe_index_stats())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ê²€ìƒ‰ í•¨ìˆ˜ (Cell 26 ìš”ì•½)\n",
        "import re, numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from config import EMBEDDING_MODEL_NAME\n",
        "\n",
        "model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=\"cpu\")\n",
        "\n",
        "def simple_tokenize(s: str):\n",
        "    return re.findall(r\"[A-Za-z0-9ê°€-í£]+\", (s or \"\").lower())\n",
        "\n",
        "def vector_search(query: str, top_k: int = 50, meta_filter=None):\n",
        "    q_vec = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
        "    kwargs = {\"vector\": q_vec.tolist(), \"top_k\": top_k, \"include_values\": False, \"include_metadata\": True}\n",
        "    if meta_filter:\n",
        "        kwargs[\"filter\"] = meta_filter\n",
        "    res = index.query(**kwargs)\n",
        "    return [(m[\"id\"], float(m[\"score\"]), m.get(\"metadata\", {})) for m in res.get(\"matches\", [])]\n",
        "\n",
        "def bm25_over_candidates(query: str, candidates):\n",
        "    ids, docs = [], []\n",
        "    for cid, _, meta in candidates:\n",
        "        text = (meta or {}).get(\"text_content\") or \"\"\n",
        "        if not text:\n",
        "            title = (meta or {}).get(\"title\") or \"\"\n",
        "            keywords = (meta or {}).get(\"keywords\") or \"\"\n",
        "            text = f\"{title}\\n{keywords}\"\n",
        "        ids.append(cid)\n",
        "        docs.append(simple_tokenize(text))\n",
        "    if not docs:\n",
        "        return {}\n",
        "    bm25 = BM25Okapi(docs)\n",
        "    scores = bm25.get_scores(simple_tokenize(query)) if query else np.zeros(len(ids))\n",
        "    max_b = float(np.max(scores)) if len(scores) else 0.0\n",
        "    return {ids[i]: (float(scores[i])/max_b if max_b>0 else 0.0) for i in range(len(ids))}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ê°œì„ ëœ ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\n",
            "ğŸ¤– ê°œì„ ëœ RAG ì±—ë´‡ (exit/quit/ì¢…ë£Œë¡œ ì™„ì „ ì¢…ë£Œ)\n",
            "============================================================\n",
            "\n",
            "ì²˜ë¦¬ ì¤‘...â³\n",
            "==========================================================================================\n",
            "[ì§ˆë¬¸] z\n",
            "\n",
            "ì²˜ë¦¬ ì¤‘...â³\n",
            "==========================================================================================\n",
            "[ì§ˆë¬¸] z\n",
            "[ë²¡í„° í›„ë³´ ìˆ˜] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8182 | í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.8149 | CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 0.8008 | ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 0.8005 | ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤ | alroebaiotigseu-chunk-12\n",
            "   5. 0.7980 | ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸ | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "   6. 0.7964 | ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   7. 0.7911 | ë…ì ê°œë°œ í•µì‹¬ ì„±ë¶„ | 3_3_4_proprietary_ingredients_univestin_uniwhite-chunk-2\n",
            "   8. 0.7882 | ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   9. 0.7869 | W389 ë”ë§ˆ ë¸Œë¼ì´íŠ¸ë‹ ì„ í¬ë¦¼ | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "  10. 0.7867 | ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜] 5\n",
            "   1. í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤ | alroebaiotigseu-chunk-12\n",
            "   5. ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸ | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´] 102\n",
            "==========================================================================================\n",
            "[ë²¡í„° í›„ë³´ ìˆ˜] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.8182 | í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.8149 | CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. 0.8008 | ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. 0.8005 | ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤ | alroebaiotigseu-chunk-12\n",
            "   5. 0.7980 | ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸ | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "   6. 0.7964 | ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   7. 0.7911 | ë…ì ê°œë°œ í•µì‹¬ ì„±ë¶„ | 3_3_4_proprietary_ingredients_univestin_uniwhite-chunk-2\n",
            "   8. 0.7882 | ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   9. 0.7869 | W389 ë”ë§ˆ ë¸Œë¼ì´íŠ¸ë‹ ì„ í¬ë¦¼ | w389_deoma_beuraiteuning_seonkeurim-chunk-4\n",
            "  10. 0.7867 | ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜] 5\n",
            "   1. í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   3. ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   4. ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤ | alroebaiotigseu-chunk-12\n",
            "   5. ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸ | 2_7_ecommerce_expansion_story_detail-chunk-2\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´] 102\n",
            "==========================================================================================\n",
            "\n",
            "ğŸ’¬ ë‹µë³€:\n",
            "------------------------------------------------------------\n",
            "ì§ˆë¬¸ \"z\"ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
            "\n",
            "ì¶œì²˜:\n",
            "- [#1] í™ì‚¼ì•¡ê³¨ë“œ\n",
            "- [#2] CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼)\n",
            "- [#3] ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬\n",
            "- [#4] ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤\n",
            "- [#5] ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸\n",
            "------------------------------------------------------------\n",
            "\n",
            "ğŸ’¬ ë‹µë³€:\n",
            "------------------------------------------------------------\n",
            "ì§ˆë¬¸ \"z\"ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.\n",
            "\n",
            "ì¶œì²˜:\n",
            "- [#1] í™ì‚¼ì•¡ê³¨ë“œ\n",
            "- [#2] CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼)\n",
            "- [#3] ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬\n",
            "- [#4] ì•Œë¡œì—ë°”ì´ì˜¤í‹±ìŠ¤\n",
            "- [#5] ì´ì»¤ë¨¸ìŠ¤ í™•ì¥ ìŠ¤í† ë¦¬ ìƒì„¸\n",
            "------------------------------------------------------------\n",
            "\n",
            "ì²˜ë¦¬ ì¤‘...â³\n",
            "==========================================================================================\n",
            "[ì§ˆë¬¸] ezit\n",
            "\n",
            "ì²˜ë¦¬ ì¤‘...â³\n",
            "==========================================================================================\n",
            "[ì§ˆë¬¸] ezit\n",
            "[ë²¡í„° í›„ë³´ ìˆ˜] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.7876 | í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.7843 | ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 0.7799 | ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 0.7789 | ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "   5. 0.7743 | ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   6. 0.7732 | CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   7. 0.7695 | 2010ë…„ëŒ€: ì§€ì†ê°€ëŠ¥ê²½ì˜ ê°•í™” ë° ê¸€ë¡œë²Œ ì¸ì¦ í™•ëŒ€ | 2_2_5_2010s_sustainability_and_global_certification-chunk-2\n",
            "   8. 0.7691 | ì¤‘êµ­ í•˜ì´ë‚œ ë†ì¥ | 3_2_5_china_hainan_farm-chunk-1\n",
            "   9. 0.7675 | ìœ ë‹ˆë² ë¼ ìœ ì‚°ê·  í”ŒëŸ¬ìŠ¤ | yusangyunpeulreoseu-chunk-5\n",
            "  10. 0.7671 | ì—ì´ì§€ì—‘ìŠ¤ | eijiegseu-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜] 5\n",
            "   1. í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "   5. ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´] 161\n",
            "==========================================================================================\n",
            "[ë²¡í„° í›„ë³´ ìˆ˜] 50\n",
            "------------------------------------------------------------------------------------------\n",
            "[Vector Top 10]\n",
            "   1. 0.7876 | í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. 0.7843 | ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. 0.7799 | ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. 0.7789 | ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "   5. 0.7743 | ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "   6. 0.7732 | CAP í”„ë¡œì íŠ¸ ìƒì„¸ (1ê¸°~5ê¸° ì„±ê³¼) | 3_3_1_cap_project_detail_phases1to5-chunk-3\n",
            "   7. 0.7695 | 2010ë…„ëŒ€: ì§€ì†ê°€ëŠ¥ê²½ì˜ ê°•í™” ë° ê¸€ë¡œë²Œ ì¸ì¦ í™•ëŒ€ | 2_2_5_2010s_sustainability_and_global_certification-chunk-2\n",
            "   8. 0.7691 | ì¤‘êµ­ í•˜ì´ë‚œ ë†ì¥ | 3_2_5_china_hainan_farm-chunk-1\n",
            "   9. 0.7675 | ìœ ë‹ˆë² ë¼ ìœ ì‚°ê·  í”ŒëŸ¬ìŠ¤ | yusangyunpeulreoseu-chunk-5\n",
            "  10. 0.7671 | ì—ì´ì§€ì—‘ìŠ¤ | eijiegseu-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜] 5\n",
            "   1. í™ì‚¼ì•¡ê³¨ë“œ | hongsamaeggoldeu-chunk-4\n",
            "   2. ì•Œë¡œì—” ë”ê³¨ë“œ í”Œë£¨ì´ë“œ | alroen_deogoldeu_peulruideu-chunk-3\n",
            "   3. ì•Œë¡œì—” ë¦¬ë°”ì´íƒˆ ëª¨ë¸ë§ íŒ© | alroen_ribaital_modelring_paeg-chunk-2\n",
            "   4. ì£¼ìš” ë¸Œëœë“œ ì•„ì´ë´í‹°í‹° | 4_3_brand_identity-chunk-1\n",
            "   5. ìœ¤ë¦¬ê²½ì˜ ë° UNGC ì°¸ì—¬ | 5_3_2_ethical_management_and_ungc-chunk-3\n",
            "------------------------------------------------------------------------------------------\n",
            "[ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´] 161\n",
            "==========================================================================================\n",
            "\n",
            "ğŸ’¬ ë‹µë³€:\n",
            "------------------------------------------------------------\n",
            "\"ezit\"ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ëŠ” ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \n",
            "\n",
            "ì¶œì²˜:\n",
            "- [#3] ê³µëœ íŒŒì¼ì—ì„œ í•´ë‹¹ ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
            "------------------------------------------------------------\n",
            "\n",
            "ğŸ’¬ ë‹µë³€:\n",
            "------------------------------------------------------------\n",
            "\"ezit\"ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ëŠ” ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. \n",
            "\n",
            "ì¶œì²˜:\n",
            "- [#3] ê³µëœ íŒŒì¼ì—ì„œ í•´ë‹¹ ì œí’ˆì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
            "------------------------------------------------------------\n",
            "ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
            "\n",
            "âœ¨ ì±—ë´‡ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
            "\n",
            "âœ¨ ì±—ë´‡ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# ê°œì„ ëœ LLM ì±—ë´‡\n",
        "from collections import deque\n",
        "from typing import List, Dict, Tuple\n",
        "from openai import OpenAI\n",
        "from config import OPENAI_API_KEY, LLM_MODEL_NAME, DEFAULT_VECTOR_WEIGHT, DEFAULT_BM25_WEIGHT, DEFAULT_TOP_K, DEFAULT_CONTEXT_CHARS, DEFAULT_CONTEXT_TOP_N\n",
        "import os\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# ê°œì„ ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
        "SYSTEM_PROMPT = (\n",
        "    \"ë„ˆëŠ” RAG ê¸°ë°˜ ë„ìš°ë¯¸ì•¼. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìš°ì„  í™œìš©í•´ì„œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´.\\n\"\n",
        "    \"ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  ë§í•´.\\n\"\n",
        "    \"ì¶œì²˜ë¥¼ bulletë¡œ í•¨ê»˜ ì œê³µí•´.\"\n",
        "    )\n",
        "\n",
        "def build_context_improved(query: str, candidates: List[Tuple[str, float, Dict]], vec_w: float, bm25_w: float, top_n: int, max_chars: int):\n",
        "    \"\"\"ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ë¹Œë”©\"\"\"\n",
        "    bm25_scores = bm25_over_candidates(query, candidates)\n",
        "    scored = []\n",
        "    for cid, v_score, meta in candidates:\n",
        "        b_score = bm25_scores.get(cid, 0.0)\n",
        "        combo = vec_w * float(v_score) + bm25_w * float(b_score)\n",
        "        scored.append((combo, cid, meta))\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "    picked, used = [], 0\n",
        "    for _, cid, meta in scored[: max(1, int(top_n) * 3)]:\n",
        "        text = (meta or {}).get(\"text_content\") or (meta or {}).get(\"title\") or \"\"\n",
        "        if not text:\n",
        "            continue\n",
        "        if used + len(text) > max_chars:\n",
        "            continue\n",
        "        picked.append({\n",
        "            \"id\": cid,\n",
        "            \"title\": (meta or {}).get(\"title\"),\n",
        "            \"source\": (meta or {}).get(\"source_doc\"),\n",
        "            \"chunk\": text,\n",
        "        })\n",
        "        used += len(text)\n",
        "        if len(picked) >= int(top_n):\n",
        "            break\n",
        "    return picked\n",
        "\n",
        "def call_openai_improved(api_key: str, model: str, messages: List[Dict]) -> str:\n",
        "    \"\"\"ê°œì„ ëœ OpenAI í˜¸ì¶œ\"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
        "    client = OpenAI(api_key=api_key)\n",
        "    r = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    return r.choices[0].message.content or \"\"\n",
        "\n",
        "_history_deque = deque(maxlen=3)\n",
        "\n",
        "def build_messages_with_history(question: str, context_text: str, citations: str) -> List[Dict[str, str]]:\n",
        "    \"\"\"ìµœê·¼ ëŒ€í™” ëª‡ í„´ì„ í¬í•¨í•˜ë„ë¡ ë©”ì‹œì§€ë¥¼ êµ¬ì„±\"\"\"\n",
        "    messages: List[Dict[str, str]] = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
        "    for past_question, past_answer, _ in _history_deque:\n",
        "        if past_question:\n",
        "            messages.append({\"role\": \"user\", \"content\": past_question})\n",
        "        if past_answer:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": past_answer})\n",
        "    user_content = (\n",
        "        f\"ì§ˆë¬¸: {question}\\n\\nì»¨í…ìŠ¤íŠ¸:\\n{context_text}\\n\\n\"\n",
        "        \"ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”. ë‹µ ëì— 'ì¶œì²˜' ì„¹ì…˜ì„ ë„£ì–´ ì•„ë˜ ëª©ë¡ì—ì„œ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ì„¸ìš”.\\n\"\n",
        "        f\"ì¶œì²˜ ëª©ë¡:\\n{citations}\"\n",
        "    )\n",
        "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
        "    return messages\n",
        "\n",
        "def chat_once_improved(question: str, vec_w=DEFAULT_VECTOR_WEIGHT, bm25_w=DEFAULT_BM25_WEIGHT, top_k=DEFAULT_TOP_K, ctx_n=DEFAULT_CONTEXT_TOP_N, max_ctx_chars=DEFAULT_CONTEXT_CHARS, debug=True):\n",
        "    \"\"\"ê°œì„ ëœ ì±—ë´‡ ë¡œì§\"\"\"\n",
        "    if debug:\n",
        "        print(\"=\"*90)\n",
        "        print(f\"[ì§ˆë¬¸] {question}\")\n",
        "\n",
        "    # ë²¡í„° ê²€ìƒ‰\n",
        "    candidates = vector_search(question, top_k=top_k)\n",
        "    \n",
        "    if debug:\n",
        "        print(f\"[ë²¡í„° í›„ë³´ ìˆ˜] {len(candidates)}\")\n",
        "        print(\"-\"*90)\n",
        "        print(\"[Vector Top 10]\")\n",
        "        for i, (cid, vscore, meta) in enumerate(candidates[:10], 1):\n",
        "            print(f\"  {i:>2}. {vscore:.4f} | {(meta or {}).get('title','N/A')} | {cid}\")\n",
        "\n",
        "    # ê°œì„ ëœ ì»¨í…ìŠ¤íŠ¸ ë¹Œë”©\n",
        "    contexts = build_context_improved(question, candidates, vec_w, bm25_w, ctx_n, max_ctx_chars)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[ì„ íƒëœ ì»¨í…ìŠ¤íŠ¸ ìˆ˜] {len(contexts)}\")\n",
        "        for i, ctx in enumerate(contexts, 1):\n",
        "            print(f\"  {i:>2}. {ctx['title'] or 'N/A'} | {ctx['id']}\")\n",
        "\n",
        "    # ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ êµ¬ì„±\n",
        "    context_text = \"\\n\\n\".join([f\"[#{i+1}] {c['chunk']}\" for i, c in enumerate(contexts)])\n",
        "    citations = \"\\n\".join(\n",
        "        [f\"- [#{i+1}] {c.get('title') or c.get('source') or c['id']}\" for i, c in enumerate(contexts)]\n",
        "    )\n",
        "\n",
        "    if debug:\n",
        "        print(\"-\"*90)\n",
        "        print(f\"[ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´] {len(context_text)}\")\n",
        "        print(\"=\"*90)\n",
        "\n",
        "    # LLM í˜¸ì¶œ\n",
        "    messages = build_messages_with_history(question, context_text, citations)\n",
        "\n",
        "    answer = call_openai_improved(\n",
        "        OPENAI_API_KEY,\n",
        "        LLM_MODEL_NAME,\n",
        "        messages,\n",
        "    )\n",
        "\n",
        "    # íˆìŠ¤í† ë¦¬ ì €ì¥\n",
        "    _history_deque.append((question, answer, \"\"))\n",
        "    \n",
        "    return answer.strip()\n",
        "\n",
        "# ========================================\n",
        "# ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ ì²´í¬\n",
        "# ========================================\n",
        "_CHATBOT_PID_FILE = \".chatbot_running.pid\"\n",
        "\n",
        "if os.path.exists(_CHATBOT_PID_FILE):\n",
        "    print(\"âš ï¸  ê²½ê³ : ì±—ë´‡ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
        "    print(\"âš ï¸  ë‹¤ë¥¸ ì»¤ë„ì—ì„œ ì‹¤í–‰ ì¤‘ì´ê±°ë‚˜ ì´ì „ ì‹¤í–‰ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"âš ï¸  í•´ê²° ë°©ë²•:\")\n",
        "    print(\"   1. Ctrl+Shift+P â†’ 'Jupyter: Restart Kernel' ì‹¤í–‰\")\n",
        "    print(\"   2. ëª¨ë“  ì…€ì„ ìˆœì°¨ì ìœ¼ë¡œ ë‹¤ì‹œ ì‹¤í–‰ (1â†’2â†’3â†’4â†’5)\")\n",
        "    raise RuntimeError(\"ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: ì»¤ë„ì„ ì¬ì‹œì‘í•˜ì„¸ìš”\")\n",
        "\n",
        "# PID íŒŒì¼ ìƒì„±\n",
        "with open(_CHATBOT_PID_FILE, \"w\") as f:\n",
        "    f.write(str(os.getpid()))\n",
        "\n",
        "print(\"âœ… ê°œì„ ëœ ì±—ë´‡ ì¤€ë¹„ ì™„ë£Œ\")\n",
        "print(\"ğŸ¤– ê°œì„ ëœ RAG ì±—ë´‡ (exit/quit/ì¢…ë£Œë¡œ ì™„ì „ ì¢…ë£Œ)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "try:\n",
        "    _running = True\n",
        "    while _running:\n",
        "        try:\n",
        "            q = input(\"\\nâ“ ì§ˆë¬¸: \").strip()\n",
        "        except (EOFError, KeyboardInterrupt):\n",
        "            print(\"\\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if q.lower() in [\"exit\",\"quit\",\"ì¢…ë£Œ\"]:\n",
        "            print(\"ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
        "            _running = False\n",
        "            break\n",
        "        \n",
        "        if not q:\n",
        "            continue\n",
        "        \n",
        "        try:\n",
        "            print(\"\\nì²˜ë¦¬ ì¤‘...â³\")\n",
        "            out = chat_once_improved(\n",
        "                q, \n",
        "                vec_w=DEFAULT_VECTOR_WEIGHT, \n",
        "                bm25_w=DEFAULT_BM25_WEIGHT, \n",
        "                top_k=DEFAULT_TOP_K, \n",
        "                ctx_n=DEFAULT_CONTEXT_TOP_N, \n",
        "                max_ctx_chars=DEFAULT_CONTEXT_CHARS,\n",
        "                debug=True\n",
        "            )\n",
        "            print(\"\\nğŸ’¬ ë‹µë³€:\")\n",
        "            print(\"-\"*60)\n",
        "            print(out)\n",
        "            print(\"-\"*60)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
        "            # ì˜¤ë¥˜ê°€ ë‚˜ë„ ë£¨í”„ëŠ” ê³„ì†\n",
        "finally:\n",
        "    # PID íŒŒì¼ ì‚­ì œ\n",
        "    if os.path.exists(_CHATBOT_PID_FILE):\n",
        "        os.remove(_CHATBOT_PID_FILE)\n",
        "    print(\"\\nâœ¨ ì±—ë´‡ì´ ì™„ì „íˆ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
