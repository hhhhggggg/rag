# app.py
import re
import numpy as np
import streamlit as st
from typing import Dict, List, Tuple

# --- deps from notebook ---
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
from openai import OpenAI

# ----------------------------
# Settings & Secrets handling
# ----------------------------

def get_secret(key: str, default: str = "") -> str:
    # ì˜¤ì§ Streamlit secrets.toml ë§Œ ì‚¬ìš©
    return st.secrets.get(key, default)  # type: ignore

DEFAULTS = {
    "EMBEDDING_MODEL_NAME": get_secret("EMBEDDING_MODEL_NAME", "sentence-transformers/all-MiniLM-L6-v2"),
    "LLM_MODEL_NAME": get_secret("LLM_MODEL_NAME", "gpt-4o-mini"),
    "PINECONE_INDEX_NAME": get_secret("PINECONE_INDEX_NAME", "YOUR_INDEX_NAME"),
    "DEFAULT_VECTOR_WEIGHT": float(get_secret("DEFAULT_VECTOR_WEIGHT", "0.7")),
    "DEFAULT_TOP_K": int(get_secret("DEFAULT_TOP_K", "50")),
    "DEFAULT_CONTEXT_TOP_N": int(get_secret("DEFAULT_CONTEXT_TOP_N", "6")),
    "DEFAULT_CONTEXT_CHARS": int(get_secret("DEFAULT_CONTEXT_CHARS", "2400")),
}

# ----------------------------
# UI â€” Page Config & Sidebar
# ----------------------------
st.set_page_config(page_title="ìœ ë‹ˆë² ë¼ ì±—ë´‡", page_icon="ğŸ¤–", layout="wide")

# CSS ì»¤ìŠ¤í„°ë§ˆì´ì§• (ChatGPT ëŠë‚Œ ë§í’ì„ )
st.markdown(
    """
    <style>
    body {
        background-color: #f7f7f8;
    }
    div[data-testid="stChatMessage"] {
        padding: 0.6rem 1rem;
        border-radius: 1rem;
        margin-bottom: 0.8rem;
        max-width: 80%;
    }
    div[data-testid="stChatMessage"][data-testid*="user"] {
        background-color: #DCF8C6;
        align-self: flex-end;
    }
    div[data-testid="stChatMessage"][data-testid*="assistant"] {
        background-color: #F1F0F0;
        align-self: flex-start;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("ğŸ¤– ìœ ë‹ˆë² ë¼ ì±—ë´‡")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")

    # --- í‚¤ ë¡œë“œ(ì…ë ¥ì¹¸ ì—†ìŒ) ---
    openai_secret = get_secret("OPENAI_API_KEY")
    pinecone_secret = get_secret("PINECONE_API_KEY")
    st.session_state.OPENAI_API_KEY = openai_secret
    st.session_state.PINECONE_API_KEY = pinecone_secret

    if openai_secret:
        st.markdown("âœ… **OpenAI API Key**: ì„¤ì •ë¨")
    else:
        st.error("âŒ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml`ì— ë„£ì–´ì£¼ì„¸ìš”.")
    if pinecone_secret:
        st.markdown("âœ… **Pinecone API Key**: ì„¤ì •ë¨")
    else:
        st.error("âŒ Pinecone API Keyê°€ ì—†ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml`ì— ë„£ì–´ì£¼ì„¸ìš”.")

    # base_urlë„ secrets.toml ì—ì„œë§Œ
    base_url = get_secret("OPENAI_BASE_URL", "")

    # ğŸ”’ ìœ„ì ¯ ì ê¸ˆ í† ê¸€ (ê¸°ë³¸: true)
    locked = str(get_secret("LOCK_SETTINGS", "true")).lower() == "true"

    st.divider()
    st.subheader("ëª¨ë¸ ì„¤ì •")
    EMBEDDING_MODEL_NAME = st.text_input(
        "Embedding ëª¨ë¸", value=DEFAULTS["EMBEDDING_MODEL_NAME"], disabled=locked
    )
    LLM_MODEL_NAME = st.text_input(
        "LLM ëª¨ë¸", value=DEFAULTS["LLM_MODEL_NAME"], disabled=locked
    )
    PINECONE_INDEX_NAME = st.text_input(
        "Pinecone ì¸ë±ìŠ¤", value=DEFAULTS["PINECONE_INDEX_NAME"], disabled=locked
    )

    st.subheader("RAG íŒŒë¼ë¯¸í„°")
    vec_w = st.slider("ë²¡í„° ê°€ì¤‘ì¹˜", 0.0, 1.0, float(DEFAULTS["DEFAULT_VECTOR_WEIGHT"]), disabled=locked)
    bm25_w = 1.0 - vec_w
    top_k = st.number_input("Vector TopK", 1, 200, int(DEFAULTS["DEFAULT_TOP_K"]), disabled=locked)
    ctx_n = st.number_input("Context TopN", 1, 20, int(DEFAULTS["DEFAULT_CONTEXT_TOP_N"]), disabled=locked)
    max_ctx_chars = st.number_input("Context ê¸¸ì´(ë¬¸ì)", 200, 8000, int(DEFAULTS["DEFAULT_CONTEXT_CHARS"]), disabled=locked)

# í‚¤ ì—†ìœ¼ë©´ ì¤‘ë‹¨
if not st.session_state.get("OPENAI_API_KEY") or not st.session_state.get("PINECONE_API_KEY"):
    st.stop()

# ----------------------------
# Caches
# ----------------------------
@st.cache_resource(show_spinner=False)
def load_embedder(name: str):
    return SentenceTransformer(name, device="cpu")

@st.cache_resource(show_spinner=True)
def init_pinecone(_api_key: str):
    if not _api_key:
        raise ValueError("Pinecone API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    return Pinecone(api_key=_api_key)

@st.cache_resource(show_spinner=False)
def get_index(_pc: Pinecone, index_name: str):
    return _pc.Index(index_name)

# ----------------------------
# RAG Core
# ----------------------------
def simple_tokenize(s: str):
    return re.findall(r"[A-Za-z0-9ê°€-í£]+", (s or "").lower())

def vector_search(index, embedder, query: str, top_k: int = 50, meta_filter=None):
    q_vec = embedder.encode([f"query: {query}"], convert_to_numpy=True, normalize_embeddings=True)[0]
    kwargs = {
        "vector": q_vec.tolist(),
        "top_k": int(top_k),
        "include_values": False,
        "include_metadata": True,
    }
    if meta_filter:
        kwargs["filter"] = meta_filter
    res = index.query(**kwargs)
    candidates = []
    for match in res.get("matches", []):
        cid = match.get("id")
        score = float(match.get("score") or 0.0)
        meta = match.get("metadata") or {}
        candidates.append((cid, score, meta))
    return candidates

def bm25_rescore(query: str, candidates: List[Tuple[str, float, Dict]]):
    ids, docs = [], []
    for cid, _, meta in candidates:
        text = (meta or {}).get("text_content") or ""
        if not text:
            title = (meta or {}).get("title") or ""
            keywords = (meta or {}).get("keywords") or ""
            text = f"{title}\n{keywords}"
        ids.append(cid)
        docs.append(simple_tokenize(text))
    if not docs:
        return {}
    bm25 = BM25Okapi(docs)
    scores = bm25.get_scores(simple_tokenize(query)) if query else np.zeros(len(ids))
    max_b = float(np.max(scores)) if len(scores) else 0.0
    return {ids[i]: (float(scores[i]) / max_b if max_b > 0 else 0.0) for i in range(len(ids))}

def build_context(query: str, candidates: List[Tuple[str, float, Dict]], vec_w: float, bm25_w: float, top_n: int, max_chars: int):
    bm25_scores = bm25_rescore(query, candidates)
    scored = []
    for cid, v_score, meta in candidates:
        b_score = bm25_scores.get(cid, 0.0)
        combo = vec_w * float(v_score) + bm25_w * float(b_score)
        scored.append((combo, cid, meta))
    scored.sort(reverse=True, key=lambda x: x[0])

    picked, used = [], 0
    for _, cid, meta in scored[: max(1, int(top_n) * 3)]:
        text = (meta or {}).get("text_content") or (meta or {}).get("title") or ""
        if not text:
            continue
        if used + len(text) > max_chars:
            continue
        picked.append({
            "id": cid,
            "title": (meta or {}).get("title"),
            "source": (meta or {}).get("source"),
            "url": (meta or {}).get("url"),
            "chunk": text,
        })
        used += len(text)
        if len(picked) >= int(top_n):
            break
    return picked

# ----------------------------
# LLM Call
# ----------------------------
def call_openai(api_key: str, model: str, messages: List[Dict], base_url: str = "") -> str:
    if not api_key:
        raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    client = OpenAI(api_key=api_key, base_url=base_url or None)
    r = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.2,
    )
    return r.choices[0].message.content or ""

SYSTEM_PROMPT = (
    "ë„ˆëŠ” RAG ê¸°ë°˜ ë„ìš°ë¯¸ì•¼. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìš°ì„  í™œìš©í•´ì„œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•´.\n"
    "ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  ë§í•´.\n"
    "ì¶œì²˜ë¥¼ bulletë¡œ í•¨ê»˜ ì œê³µí•´."
)

# ----------------------------
# Chat UI
# ----------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []

chat_container = st.container()

with chat_container:
    for m in st.session_state.messages:
        if m["role"] == "user":
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(m["content"])
        else:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown(m["content"])

user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(user_input)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                embedder = load_embedder(EMBEDDING_MODEL_NAME)
                pc = init_pinecone(st.session_state.PINECONE_API_KEY)
                index = get_index(pc, PINECONE_INDEX_NAME)

                candidates = vector_search(index, embedder, user_input, top_k=top_k)
                contexts = build_context(user_input, candidates, vec_w, bm25_w, ctx_n, max_ctx_chars)

                context_text = "\n\n".join([f"[#{i+1}] {c['chunk']}" for i, c in enumerate(contexts)])
                citations = "\n".join(
                    [f"- [#{i+1}] {c.get('title') or c.get('source') or c.get('url') or c['id']}" for i, c in enumerate(contexts)]
                )

                messages = [
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": (
                            f"ì§ˆë¬¸: {user_input}\n\nì»¨í…ìŠ¤íŠ¸:\n{context_text}\n\n"
                            "ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”. ë‹µ ëì— 'ì¶œì²˜' ì„¹ì…˜ì„ ë„£ì–´ ì•„ë˜ ëª©ë¡ì—ì„œ ê·¼ê±°ë¥¼ ì¸ìš©í•˜ì„¸ìš”.\n"
                            f"ì¶œì²˜ ëª©ë¡:\n{citations}"
                        ),
                    },
                ]

                answer = call_openai(
                    st.session_state.OPENAI_API_KEY,
                    LLM_MODEL_NAME,
                    messages,
                    base_url=base_url,
                )

                final = answer.strip()
                st.markdown(final)
                st.session_state.messages.append({"role": "assistant", "content": final})

            except Exception as e:
                st.error(f"ì˜¤ë¥˜: {e}")
