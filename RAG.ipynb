{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3448467",
   "metadata": {},
   "source": [
    "# Cell 0: RAG 시스템 구축 (CPU, Pinecone + E5)\n",
    "\n",
    "## 📋 개요\n",
    "이 노트북은 **Retrieval-Augmented Generation (RAG)** 시스템을 구축하는 완전한 가이드입니다.\n",
    "\n",
    "### 🎯 주요 기능\n",
    "- **문서 처리**: 마크다운 파일에서 front-matter와 본문 분리\n",
    "- **텍스트 청킹**: 500자 단위로 텍스트 분할 (75자 오버랩)\n",
    "- **임베딩 생성**: E5-base-v2 모델로 벡터 임베딩 생성\n",
    "- **벡터 저장**: Pinecone 서버리스 인덱스에 벡터 저장\n",
    "- **하이브리드 검색**: 벡터 검색 + BM25 키워드 검색 결합\n",
    "- **재랭킹**: CrossEncoder로 검색 결과 재정렬\n",
    "- **답변 생성**: OpenAI GPT-4o-mini로 컨텍스트 기반 답변 생성\n",
    "\n",
    "### 🔧 기술 스택\n",
    "- **임베딩 모델**: `intfloat/e5-base-v2` (768차원)\n",
    "- **벡터 DB**: Pinecone (서버리스)\n",
    "- **재랭킹**: `cross-encoder/ms-marco-MiniLM-L-6-v2`\n",
    "- **LLM**: OpenAI GPT-4o-mini\n",
    "- **언어**: Python 3.11+ (CPU 전용)\n",
    "\n",
    "### 📁 데이터 구조\n",
    "```\n",
    "문서 → Front-matter + 본문 → 청킹 → 임베딩 → Pinecone 저장\n",
    "```\n",
    "\n",
    "> **주의**: CPU 환경에서 실행되며, 한글 파일명은 자동으로 ASCII로 변환됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055cd54f",
   "metadata": {},
   "source": [
    "## Cell 1: 🔍 1. 환경 확인\n",
    "\n",
    "Python 환경과 주요 라이브러리 버전을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15890087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n",
      "Platform: Windows-10-10.0.26100-SP0\n",
      "Torch: 2.8.0+cpu | CUDA 사용 여부: False\n",
      "Transformers: 4.56.1\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: 환경 확인 코드\n",
    "import sys, platform\n",
    "print('Python:', sys.version)\n",
    "print('Platform:', platform.platform())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print('Torch:', torch.__version__, '| CUDA 사용 여부:', torch.cuda.is_available())\n",
    "except Exception as e:\n",
    "    print('Torch 미설치 또는 오류:', e)\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print('Transformers:', transformers.__version__)\n",
    "except Exception as e:\n",
    "    print('Transformers 미설치 또는 오류:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2b4b8",
   "metadata": {},
   "source": [
    "## Cell 3: 📦 2. 필수 패키지 설치\n",
    "\n",
    "RAG 시스템에 필요한 핵심 패키지들을 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4bf5e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설치 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: 패키지 설치 코드\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade pip\n",
    "!{sys.executable} -m pip install -q \"pinecone>=5.0.0\" sentence-transformers\n",
    "print(\"설치 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcbb08",
   "metadata": {},
   "source": [
    "## Cell 5: 🗄️ 3. Pinecone 설정\n",
    "\n",
    "### 사전 준비\n",
    "1. [Pinecone](https://www.pinecone.io) 무료 계정 가입\n",
    "2. API 키 발급 및 환경변수 설정: `PINECONE_API_KEY`\n",
    "3. OpenAI API 키 설정: `OPENAI_API_KEY`\n",
    "\n",
    "### 인덱스 생성\n",
    "- **이름**: `rag-uv-chatbot`\n",
    "- **차원**: 768 (E5-base-v2 출력 차원)\n",
    "- **메트릭**: cosine similarity\n",
    "- **클라우드**: AWS us-east-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bd4fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미 인덱스 있음\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Pinecone 인덱스 생성/연결\n",
    "import os \n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# 🔑 PINECONE API KEY\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "\n",
    "# 인덱스 이름 지정 (소문자, 하이픈만 허용)\n",
    "index_name = \"rag-univera-chatbot-v2\"\n",
    "\n",
    "# 인덱스 없으면 생성\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,  # multilingual-e5-large 출력 차원\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(\"인덱스 생성 완료\")\n",
    "else:\n",
    "    print(\"이미 인덱스 있음\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b694afa",
   "metadata": {},
   "source": [
    "## Cell 7: 🔧 4. ID 변환 (Pinecone 호환)\n",
    "\n",
    "Pinecone은 벡터 ID에 ASCII 문자만 허용하므로, 한글 파일명을 ASCII로 변환합니다.\n",
    "\n",
    "### 변환 예시\n",
    "- `'M40X_마일드_클렌징_오일-front'` → `'m40x_maildeu_keulrenjing_oil-front'`\n",
    "- `'한글_문서-chunk-0'` → `'hangeul_munseo-chunk-0'`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3756ff",
   "metadata": {},
   "source": [
    "## Cell 8: 📊 5. 인덱스 상태 확인\n",
    "\n",
    "Pinecone 인덱스의 현재 상태를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b7095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 703}},\n",
      " 'total_vector_count': 703,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: 인덱스 상태 확인\n",
    "index = pc.Index(index_name)\n",
    "print(index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce44a2bb",
   "metadata": {},
   "source": [
    "## Cell 10: 📁 6. 문서 처리 파이프라인\n",
    "\n",
    "### 처리 단계\n",
    "1. **파일 수집**: 지정된 폴더에서 모든 `.md` 파일 수집\n",
    "2. **텍스트 파싱**: Front-matter와 본문 분리\n",
    "3. **텍스트 청킹**: 500자 단위로 분할 (75자 오버랩)\n",
    "4. **메타데이터 추출**: 제목, 카테고리, 키워드 등 추출\n",
    "5. **임베딩 생성**: E5-base-v2 모델로 벡터 생성\n",
    "6. **벡터 저장**: Pinecone에 배치 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b77fa7",
   "metadata": {},
   "source": [
    "## Cell 11: 📂 6.1 파일 수집\n",
    "\n",
    "재귀적으로 모든 하위 폴더에서 마크다운 파일을 수집합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b162af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제품 정보 폴더 마크다운 파일 수: 90\n",
      "회사 정보 폴더 마크다운 파일 수: 63\n",
      "전체 마크다운 파일 수: 153\n",
      "예시: ['C:\\\\Users\\\\admin\\\\Desktop\\\\문서\\\\9999.DDP\\\\RAG Database_Products Info (90 files)\\\\M40X_마일드_클렌징_오일.md', 'C:\\\\Users\\\\admin\\\\Desktop\\\\문서\\\\9999.DDP\\\\RAG Database_Products Info (90 files)\\\\M40X_마일드_폼_클렌져.md', 'C:\\\\Users\\\\admin\\\\Desktop\\\\문서\\\\9999.DDP\\\\RAG Database_Products Info (90 files)\\\\New알로에버플러스.md', 'C:\\\\Users\\\\admin\\\\Desktop\\\\문서\\\\9999.DDP\\\\RAG Database_Products Info (90 files)\\\\W389_더마_브라이트닝.md', 'C:\\\\Users\\\\admin\\\\Desktop\\\\문서\\\\9999.DDP\\\\RAG Database_Products Info (90 files)\\\\W389_더마_브라이트닝_로션.md']\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: 파일 수집 코드\n",
    "import os, re, json\n",
    "\n",
    "# 새로운 폴더 경로\n",
    "folder_path1 = r\"C:\\Users\\admin\\Desktop\\문서\\9999.DDP\\RAG Database_Products Info (90 files)\"\n",
    "folder_path2 = r\"C:\\Users\\admin\\Desktop\\문서\\9999.DDP\\RAG Database_Company Info (63 files)\"\n",
    "\n",
    "def find_md_files_direct(folder_path):\n",
    "    \"\"\"폴더에서 직접 .md 파일 찾기 (재귀 없음)\"\"\"\n",
    "    md_files = []\n",
    "    if os.path.exists(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith(\".md\"):\n",
    "                md_files.append(os.path.join(folder_path, file))\n",
    "    return md_files\n",
    "\n",
    "# 두 폴더에서 마크다운 파일 수집\n",
    "md_files1 = find_md_files_direct(folder_path1)\n",
    "md_files2 = find_md_files_direct(folder_path2)\n",
    "\n",
    "# 모든 마크다운 파일 합치기\n",
    "md_files = md_files1 + md_files2\n",
    "\n",
    "print(\"제품 정보 폴더 마크다운 파일 수:\", len(md_files1))\n",
    "print(\"회사 정보 폴더 마크다운 파일 수:\", len(md_files2))\n",
    "print(\"전체 마크다운 파일 수:\", len(md_files))\n",
    "print(\"예시:\", md_files[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6351714",
   "metadata": {},
   "source": [
    "### 6.2 텍스트 파싱\n",
    "\n",
    "마크다운 파일에서 front-matter와 본문을 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7605b7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 파싱 완료 | M40X_마일드_클렌징_오일.md\n",
      "✅ 파싱 완료 | M40X_마일드_폼_클렌져.md\n",
      "✅ 파싱 완료 | New알로에버플러스.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_로션.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_선크림.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_선크림_기획세트.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_스팟_에센스.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_크림.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_토너.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_필링젤.md\n",
      "✅ 파싱 완료 | 그린칼슘플러스.md\n",
      "✅ 파싱 완료 | 남양931플러스.md\n",
      "✅ 파싱 완료 | 노회비책.md\n",
      "✅ 파싱 완료 | 레벨지플러스.md\n",
      "✅ 파싱 완료 | 리제니케어A.md\n",
      "✅ 파싱 완료 | 멀티비타민_맥스.md\n",
      "✅ 파싱 완료 | 메타번슬림핏.md\n",
      "✅ 파싱 완료 | 미즈에버플러스.md\n",
      "✅ 파싱 완료 | 베라힐.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_(바디로션,바디워시,샴푸,시크릿케어).md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디로션.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디미스트.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디워시.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_샴푸.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_시크릿케어.md\n",
      "✅ 파싱 완료 | 베라힐_토탈케어_치약.md\n",
      "✅ 파싱 완료 | 베라힐퍼퓸드핸드크림.md\n",
      "✅ 파싱 완료 | 비움클렌즈.md\n",
      "✅ 파싱 완료 | 빌리브뷰티콜라겐.md\n",
      "✅ 파싱 완료 | 빌리브웰니스푸드S.md\n",
      "✅ 파싱 완료 | 빌리브효소.md\n",
      "✅ 파싱 완료 | 수면온.md\n",
      "✅ 파싱 완료 | 슈퍼겔맥스.md\n",
      "✅ 파싱 완료 | 아레지오플러스.md\n",
      "✅ 파싱 완료 | 아보민플러스.md\n",
      "✅ 파싱 완료 | 알로맥프로지.md\n",
      "✅ 파싱 완료 | 알로신.md\n",
      "✅ 파싱 완료 | 알로에바이오틱스.md\n",
      "✅ 파싱 완료 | 알로에버플러스.md\n",
      "✅ 파싱 완료 | 알로에테라샷.md\n",
      "✅ 파싱 완료 | 알로엑스_액티브_알로에겔.md\n",
      "✅ 파싱 완료 | 알로엔_더_골드_안티에이징.md\n",
      "✅ 파싱 완료 | 알로엔_더_블루_미스트.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_아이크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징(플루이드,앰플,아이크림,크림).md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_아이크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_플루이드.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_플루이드.md\n",
      "✅ 파싱 완료 | 알로엔_더블루.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_기초.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징(오일,폼).md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징_오일.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징_폼.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_로션.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_로션.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_세럼.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_크림미스트.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_토너.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_세럼.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_SOS크림.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_수딩스틱.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_스킨케어100.md\n",
      "✅ 파싱 완료 | 알로엔_리바이탈_모델링_팩.md\n",
      "✅ 파싱 완료 | 알로엔_립_세럼_스틱.md\n",
      "✅ 파싱 완료 | 알로엔_립_세럼_스틱_(한정판_오렌지_코랄).md\n",
      "✅ 파싱 완료 | 알로엔_모이스처_라인.md\n",
      "✅ 파싱 완료 | 알로엔_모이스처_캡슐젤.md\n",
      "✅ 파싱 완료 | 알로엔_비비크림.md\n",
      "✅ 파싱 완료 | 알로엔_수딩_마스크팩.md\n",
      "✅ 파싱 완료 | 알로엔_스킨커버.md\n",
      "✅ 파싱 완료 | 알로엔_안티_헤어로스_샴푸_&_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_톤업크림.md\n",
      "✅ 파싱 완료 | 알로청플러스.md\n",
      "✅ 파싱 완료 | 알브라이트플러스.md\n",
      "✅ 파싱 완료 | 알키드_징크.md\n",
      "✅ 파싱 완료 | 에이지엑스.md\n",
      "✅ 파싱 완료 | 유산균플러스.md\n",
      "✅ 파싱 완료 | 채움프로틴.md\n",
      "✅ 파싱 완료 | 파이토클린샷.md\n",
      "✅ 파싱 완료 | 항균프로폴리스.md\n",
      "✅ 파싱 완료 | 홍삼액골드.md\n",
      "✅ 파싱 완료 | 홍삼액키즈.md\n",
      "✅ 파싱 완료 | 흑삼기력데일리.md\n",
      "✅ 파싱 완료 | 흑삼기력프리미엄.md\n",
      "✅ 파싱 완료 | 1-1_Univera Mission and Vision.md\n",
      "✅ 파싱 완료 | 1-2_Founder_Background_and_Philosophy.md\n",
      "✅ 파싱 완료 | 1-3_CEO_Message.md\n",
      "✅ 파싱 완료 | 1_Corporate_Philosophy.md\n",
      "✅ 파싱 완료 | 2-1_Overall_History.md\n",
      "✅ 파싱 완료 | 2-2-1_1970s_Founding_and_Challenges.md\n",
      "✅ 파싱 완료 | 2-2-2_1980s_Global_Expansion.md\n",
      "✅ 파싱 완료 | 2-2-3_1990s_RnD_Strengthening.md\n",
      "✅ 파싱 완료 | 2-2-4_2000s_Wellness_Leap.md\n",
      "✅ 파싱 완료 | 2-2-5_2010s_Sustainability_and_Global_Certification.md\n",
      "✅ 파싱 완료 | 2-2-6_2020s_Brand_Expansion_and_Ecommerce_Transition.md\n",
      "✅ 파싱 완료 | 2-2_History_by_Year.md\n",
      "✅ 파싱 완료 | 2-3_Domestic_Business_Expansion_History.md\n",
      "✅ 파싱 완료 | 2-4_Overseas_Expansion_History.md\n",
      "✅ 파싱 완료 | 2-5_RnD_History_Detail.md\n",
      "✅ 파싱 완료 | 2-6_Brand_Expansion_Story_Detail.md\n",
      "✅ 파싱 완료 | 2-7_Ecommerce_Expansion_Story_Detail.md\n",
      "✅ 파싱 완료 | 2_Corporate_History.md\n",
      "✅ 파싱 완료 | 3-1_Econet_System_Overview.md\n",
      "✅ 파싱 완료 | 3-2-1_Mexico_Farm_Campeche.md\n",
      "✅ 파싱 완료 | 3-2-2_Mexico_Farm_Gonzalez.md\n",
      "✅ 파싱 완료 | 3-2-3_USA_Hilltop_Gardens.md\n",
      "✅ 파싱 완료 | 3-2-4_Russia_Kraskino_Farm.md\n",
      "✅ 파싱 완료 | 3-2-5_China_Hainan_Farm.md\n",
      "✅ 파싱 완료 | 3-2_Cultivation_Aloecorp.md\n",
      "✅ 파싱 완료 | 3-3-1_CAP_Project_Detail_Phases1to5.md\n",
      "✅ 파싱 완료 | 3-3-2_Core_Technology_PhytoLogix.md\n",
      "✅ 파싱 완료 | 3-3-3_Aloe_Processing_Innovation_Generations1to5.md\n",
      "✅ 파싱 완료 | 3-3-4_Proprietary_Ingredients_Univestin_Uniwhite.md\n",
      "✅ 파싱 완료 | 3-3_RnD_Subsidiary_Unigen.md\n",
      "✅ 파싱 완료 | 3-4-1_Naturetech_Overview.md\n",
      "✅ 파싱 완료 | 3-4-2_Naturetech_Production_Facilities.md\n",
      "✅ 파싱 완료 | 3-4-3_Naturetech_Certifications.md\n",
      "✅ 파싱 완료 | 3-4_Production_Subsidiary_Naturetech.md\n",
      "✅ 파싱 완료 | 3-5-1_Univera_Overview.md\n",
      "✅ 파싱 완료 | 3-5-2_DoorToDoor_Sales_History.md\n",
      "✅ 파싱 완료 | 3-5-3_DoorToDoor_Sales_Status.md\n",
      "✅ 파싱 완료 | 3-5-4_DoorToDoor_Sales_Brands_and_Products.md\n",
      "✅ 파싱 완료 | 3-5-5_Ecommerce_History_and_Status.md\n",
      "✅ 파싱 완료 | 3-5-6_Ecommerce_Brands_and_Products.md\n",
      "✅ 파싱 완료 | 3-5_Sales_Subsidiary_Univera.md\n",
      "✅ 파싱 완료 | 3_Core_Competency_Econet_System.md\n",
      "✅ 파싱 완료 | 4-1_Product_Development_Principles_Efficacy_Safety_Sustainability.md\n",
      "✅ 파싱 완료 | 4-2_Univera_Product_Portfolio.md\n",
      "✅ 파싱 완료 | 4-3-1_Brand_Univera.md\n",
      "✅ 파싱 완료 | 4-3-2_Brand_Immune.md\n",
      "✅ 파싱 완료 | 4-3-3_Brand_Botanity.md\n",
      "✅ 파싱 완료 | 4-3_Brand_Identity.md\n",
      "✅ 파싱 완료 | 4_Product_Philosophy_and_Major_Brands.md\n",
      "✅ 파싱 완료 | 5-1-1_CSR_Activities.md\n",
      "✅ 파싱 완료 | 5-1-2_Customer_Centered_Management_CCM.md\n",
      "✅ 파싱 완료 | 5-1-3_Employee_Policies.md\n",
      "✅ 파싱 완료 | 5-1-4_UP_Partner_Growth_Policies.md\n",
      "✅ 파싱 완료 | 5-1_Social.md\n",
      "✅ 파싱 완료 | 5-2-1_Environmental_Management_Philosophy_and_Strategies.md\n",
      "✅ 파싱 완료 | 5-2_Environmental.md\n",
      "✅ 파싱 완료 | 5-3-1_Corporate_Governance.md\n",
      "✅ 파싱 완료 | 5-3-2_Ethical_Management_and_UNGC.md\n",
      "✅ 파싱 완료 | 5-3_Governance_and_Ethics.md\n",
      "✅ 파싱 완료 | 5-4-1_World_Class_Product_History.md\n",
      "✅ 파싱 완료 | 5-4-2_Major_Certifications_GMP_GAP_GRAS.md\n",
      "✅ 파싱 완료 | 5-4_Quality_and_Certifications.md\n",
      "✅ 파싱 완료 | 5_Sustainability_ESG.md\n",
      "불러온 문서 수: 153\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: 텍스트 파싱 코드 (단순화)\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "def parse_document_unified(text, filename):\n",
    "    \"\"\"Front-matter 파싱 함수 (단순화)\"\"\"\n",
    "    \n",
    "    # YAML front-matter 파싱\n",
    "    fm_match = re.match(r\"^---\\s*\\n(.*?)\\n---\\s*\\n(.*)\", text, re.DOTALL)\n",
    "    if fm_match:\n",
    "        front_matter_raw, body = fm_match.groups()\n",
    "        try:\n",
    "            fm_dict = yaml.safe_load(front_matter_raw)\n",
    "            if fm_dict:\n",
    "                print(f\"✅ 파싱 완료 | {filename}\")\n",
    "                return fm_dict, body\n",
    "        except yaml.YAMLError as e:\n",
    "            print(f\"❌ YAML 파싱 오류 | {filename} - {e}\")\n",
    "    \n",
    "    # front-matter가 없으면 기본값 반환\n",
    "    print(f\"⚠️ Front-matter 없음 | {filename}\")\n",
    "    name_without_ext = os.path.splitext(filename)[0]\n",
    "    title = name_without_ext.replace('_', ' ')\n",
    "    \n",
    "    fm_dict = {\n",
    "        \"title\": title,\n",
    "        \"category1\": \"기타\",\n",
    "        \"category2\": \"\",\n",
    "        \"category3\": \"\",\n",
    "        \"category4\": \"\",\n",
    "        \"keywords\": title\n",
    "    }\n",
    "    return fm_dict, text\n",
    "\n",
    "docs = []\n",
    "for file_path in md_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # 통합 파싱 함수 사용\n",
    "    fm_dict, body = parse_document_unified(text, os.path.basename(file_path))\n",
    "    \n",
    "    docs.append({\n",
    "        \"id\": os.path.basename(file_path),\n",
    "        \"front_matter\": fm_dict,\n",
    "        \"body\": body\n",
    "    })\n",
    "\n",
    "print(\"불러온 문서 수:\", len(docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c04ed",
   "metadata": {},
   "source": [
    "# Cell 15: ⚠️ 주의: Pinecone 인덱스 초기화\n",
    "\n",
    "## 🚨 **위험한 작업입니다!**\n",
    "\n",
    "이 셀은 **Pinecone 인덱스의 모든 데이터를 영구적으로 삭제**합니다.\n",
    "\n",
    "### ⚠️ **실행 전 확인사항**\n",
    "- [ ] **백업이 필요한가요?** (현재 데이터를 보존해야 하는 경우)\n",
    "- [ ] **정말로 모든 데이터를 삭제하시겠습니까?**\n",
    "- [ ] **다른 사용자가 이 인덱스를 사용하고 있지 않나요?**\n",
    "\n",
    "### 🔄 **언제 사용하나요?**\n",
    "- 새로운 AI 기반 메타데이터로 데이터를 재처리할 때\n",
    "- 인덱스에 문제가 생겨서 완전히 초기화해야 할 때\n",
    "- 테스트용 데이터를 정리할 때\n",
    "\n",
    "### ⚡ **실행 후 해야 할 일**\n",
    "1. **Cell 1부터 순서대로 실행**하여 새로운 데이터로 재처리\n",
    "2. **대화 시스템 테스트**로 정상 작동 확인\n",
    "\n",
    "### 💡 **안전한 사용법**\n",
    "```python\n",
    "# 실행 전 현재 상태 확인\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"현재 벡터 수: {stats.total_vector_count}\")\n",
    "\n",
    "# 정말 삭제하시겠습니까? 확인 후 실행\n",
    "```\n",
    "\n",
    "---\n",
    "**⚠️ 주의: 이 작업은 되돌릴 수 없습니다!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c0a49d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Pinecone 인덱스의 모든 데이터를 삭제합니다...\n",
      "현재 벡터 수: 901\n",
      "✅ 모든 데이터 삭제 완료!\n",
      "삭제 후 벡터 수: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: 🗑️ Pinecone 인덱스 초기화 (모든 데이터 삭제)\n",
    "print(\"🗑️ Pinecone 인덱스의 모든 데이터를 삭제합니다...\")\n",
    "\n",
    "# 인덱스 연결\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# 현재 인덱스 상태 확인\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"현재 벡터 수: {stats.total_vector_count}\")\n",
    "\n",
    "# 모든 벡터 삭제\n",
    "if stats.total_vector_count > 0:\n",
    "    index.delete(delete_all=True)\n",
    "    print(\"✅ 모든 데이터 삭제 완료!\")\n",
    "    \n",
    "    # 삭제 후 상태 확인\n",
    "    stats_after = index.describe_index_stats()\n",
    "    print(f\"삭제 후 벡터 수: {stats_after.total_vector_count}\")\n",
    "else:\n",
    "    print(\"이미 비어있는 인덱스입니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7566ee0a",
   "metadata": {},
   "source": [
    "## Cell 17: ✂️ 6.3 텍스트 청킹 및 메타데이터 생성\n",
    "\n",
    "텍스트를 500자 단위로 분할하고 각 청크에 메타데이터를 추가합니다.\n",
    "\n",
    "#### 청킹 설정\n",
    "- **청크 크기**: 500자\n",
    "- **오버랩**: 75자\n",
    "- **메타데이터**: 제목, 카테고리, 키워드, 소스 문서 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "526e8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 문서 파싱 시작...\n",
      "✅ 파싱 완료 | M40X_마일드_클렌징_오일.md\n",
      "✅ 파싱 완료 | M40X_마일드_폼_클렌져.md\n",
      "✅ 파싱 완료 | New알로에버플러스.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_로션.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_선크림.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_선크림_기획세트.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_스팟_에센스.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_크림.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_토너.md\n",
      "✅ 파싱 완료 | W389_더마_브라이트닝_필링젤.md\n",
      "✅ 파싱 완료 | 그린칼슘플러스.md\n",
      "✅ 파싱 완료 | 남양931플러스.md\n",
      "✅ 파싱 완료 | 노회비책.md\n",
      "✅ 파싱 완료 | 레벨지플러스.md\n",
      "✅ 파싱 완료 | 리제니케어A.md\n",
      "✅ 파싱 완료 | 멀티비타민_맥스.md\n",
      "✅ 파싱 완료 | 메타번슬림핏.md\n",
      "✅ 파싱 완료 | 미즈에버플러스.md\n",
      "✅ 파싱 완료 | 베라힐.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_(바디로션,바디워시,샴푸,시크릿케어).md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디로션.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디미스트.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_바디워시.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_샴푸.md\n",
      "✅ 파싱 완료 | 베라힐_내추럴_마일드_시크릿케어.md\n",
      "✅ 파싱 완료 | 베라힐_토탈케어_치약.md\n",
      "✅ 파싱 완료 | 베라힐퍼퓸드핸드크림.md\n",
      "✅ 파싱 완료 | 비움클렌즈.md\n",
      "✅ 파싱 완료 | 빌리브뷰티콜라겐.md\n",
      "✅ 파싱 완료 | 빌리브웰니스푸드S.md\n",
      "✅ 파싱 완료 | 빌리브효소.md\n",
      "✅ 파싱 완료 | 수면온.md\n",
      "✅ 파싱 완료 | 슈퍼겔맥스.md\n",
      "✅ 파싱 완료 | 아레지오플러스.md\n",
      "✅ 파싱 완료 | 아보민플러스.md\n",
      "✅ 파싱 완료 | 알로맥프로지.md\n",
      "✅ 파싱 완료 | 알로신.md\n",
      "✅ 파싱 완료 | 알로에바이오틱스.md\n",
      "✅ 파싱 완료 | 알로에버플러스.md\n",
      "✅ 파싱 완료 | 알로에테라샷.md\n",
      "✅ 파싱 완료 | 알로엑스_액티브_알로에겔.md\n",
      "✅ 파싱 완료 | 알로엔_더_골드_안티에이징.md\n",
      "✅ 파싱 완료 | 알로엔_더_블루_미스트.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_아이크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징(플루이드,앰플,아이크림,크림).md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_아이크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_안티에이징_플루이드.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더골드_플루이드.md\n",
      "✅ 파싱 완료 | 알로엔_더블루.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_기초.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징(오일,폼).md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징_오일.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_딥클렌징_폼.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_로션.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_로션.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_세럼.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_크림.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_크림미스트.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_모이스처_토너.md\n",
      "✅ 파싱 완료 | 알로엔_더블루_세럼.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_SOS크림.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_수딩스틱.md\n",
      "✅ 파싱 완료 | 알로엔_디오리진_스킨케어100.md\n",
      "✅ 파싱 완료 | 알로엔_리바이탈_모델링_팩.md\n",
      "✅ 파싱 완료 | 알로엔_립_세럼_스틱.md\n",
      "✅ 파싱 완료 | 알로엔_립_세럼_스틱_(한정판_오렌지_코랄).md\n",
      "✅ 파싱 완료 | 알로엔_모이스처_라인.md\n",
      "✅ 파싱 완료 | 알로엔_모이스처_캡슐젤.md\n",
      "✅ 파싱 완료 | 알로엔_비비크림.md\n",
      "✅ 파싱 완료 | 알로엔_수딩_마스크팩.md\n",
      "✅ 파싱 완료 | 알로엔_스킨커버.md\n",
      "✅ 파싱 완료 | 알로엔_안티_헤어로스_샴푸_&_앰플.md\n",
      "✅ 파싱 완료 | 알로엔_톤업크림.md\n",
      "✅ 파싱 완료 | 알로청플러스.md\n",
      "✅ 파싱 완료 | 알브라이트플러스.md\n",
      "✅ 파싱 완료 | 알키드_징크.md\n",
      "✅ 파싱 완료 | 에이지엑스.md\n",
      "✅ 파싱 완료 | 유산균플러스.md\n",
      "✅ 파싱 완료 | 채움프로틴.md\n",
      "✅ 파싱 완료 | 파이토클린샷.md\n",
      "✅ 파싱 완료 | 항균프로폴리스.md\n",
      "✅ 파싱 완료 | 홍삼액골드.md\n",
      "✅ 파싱 완료 | 홍삼액키즈.md\n",
      "✅ 파싱 완료 | 흑삼기력데일리.md\n",
      "✅ 파싱 완료 | 흑삼기력프리미엄.md\n",
      "✅ 파싱 완료 | 1-1_Univera Mission and Vision.md\n",
      "✅ 파싱 완료 | 1-2_Founder_Background_and_Philosophy.md\n",
      "✅ 파싱 완료 | 1-3_CEO_Message.md\n",
      "✅ 파싱 완료 | 1_Corporate_Philosophy.md\n",
      "✅ 파싱 완료 | 2-1_Overall_History.md\n",
      "✅ 파싱 완료 | 2-2-1_1970s_Founding_and_Challenges.md\n",
      "✅ 파싱 완료 | 2-2-2_1980s_Global_Expansion.md\n",
      "✅ 파싱 완료 | 2-2-3_1990s_RnD_Strengthening.md\n",
      "✅ 파싱 완료 | 2-2-4_2000s_Wellness_Leap.md\n",
      "✅ 파싱 완료 | 2-2-5_2010s_Sustainability_and_Global_Certification.md\n",
      "✅ 파싱 완료 | 2-2-6_2020s_Brand_Expansion_and_Ecommerce_Transition.md\n",
      "✅ 파싱 완료 | 2-2_History_by_Year.md\n",
      "✅ 파싱 완료 | 2-3_Domestic_Business_Expansion_History.md\n",
      "✅ 파싱 완료 | 2-4_Overseas_Expansion_History.md\n",
      "✅ 파싱 완료 | 2-5_RnD_History_Detail.md\n",
      "✅ 파싱 완료 | 2-6_Brand_Expansion_Story_Detail.md\n",
      "✅ 파싱 완료 | 2-7_Ecommerce_Expansion_Story_Detail.md\n",
      "✅ 파싱 완료 | 2_Corporate_History.md\n",
      "✅ 파싱 완료 | 3-1_Econet_System_Overview.md\n",
      "✅ 파싱 완료 | 3-2-1_Mexico_Farm_Campeche.md\n",
      "✅ 파싱 완료 | 3-2-2_Mexico_Farm_Gonzalez.md\n",
      "✅ 파싱 완료 | 3-2-3_USA_Hilltop_Gardens.md\n",
      "✅ 파싱 완료 | 3-2-4_Russia_Kraskino_Farm.md\n",
      "✅ 파싱 완료 | 3-2-5_China_Hainan_Farm.md\n",
      "✅ 파싱 완료 | 3-2_Cultivation_Aloecorp.md\n",
      "✅ 파싱 완료 | 3-3-1_CAP_Project_Detail_Phases1to5.md\n",
      "✅ 파싱 완료 | 3-3-2_Core_Technology_PhytoLogix.md\n",
      "✅ 파싱 완료 | 3-3-3_Aloe_Processing_Innovation_Generations1to5.md\n",
      "✅ 파싱 완료 | 3-3-4_Proprietary_Ingredients_Univestin_Uniwhite.md\n",
      "✅ 파싱 완료 | 3-3_RnD_Subsidiary_Unigen.md\n",
      "✅ 파싱 완료 | 3-4-1_Naturetech_Overview.md\n",
      "✅ 파싱 완료 | 3-4-2_Naturetech_Production_Facilities.md\n",
      "✅ 파싱 완료 | 3-4-3_Naturetech_Certifications.md\n",
      "✅ 파싱 완료 | 3-4_Production_Subsidiary_Naturetech.md\n",
      "✅ 파싱 완료 | 3-5-1_Univera_Overview.md\n",
      "✅ 파싱 완료 | 3-5-2_DoorToDoor_Sales_History.md\n",
      "✅ 파싱 완료 | 3-5-3_DoorToDoor_Sales_Status.md\n",
      "✅ 파싱 완료 | 3-5-4_DoorToDoor_Sales_Brands_and_Products.md\n",
      "✅ 파싱 완료 | 3-5-5_Ecommerce_History_and_Status.md\n",
      "✅ 파싱 완료 | 3-5-6_Ecommerce_Brands_and_Products.md\n",
      "✅ 파싱 완료 | 3-5_Sales_Subsidiary_Univera.md\n",
      "✅ 파싱 완료 | 3_Core_Competency_Econet_System.md\n",
      "✅ 파싱 완료 | 4-1_Product_Development_Principles_Efficacy_Safety_Sustainability.md\n",
      "✅ 파싱 완료 | 4-2_Univera_Product_Portfolio.md\n",
      "✅ 파싱 완료 | 4-3-1_Brand_Univera.md\n",
      "✅ 파싱 완료 | 4-3-2_Brand_Immune.md\n",
      "✅ 파싱 완료 | 4-3-3_Brand_Botanity.md\n",
      "✅ 파싱 완료 | 4-3_Brand_Identity.md\n",
      "✅ 파싱 완료 | 4_Product_Philosophy_and_Major_Brands.md\n",
      "✅ 파싱 완료 | 5-1-1_CSR_Activities.md\n",
      "✅ 파싱 완료 | 5-1-2_Customer_Centered_Management_CCM.md\n",
      "✅ 파싱 완료 | 5-1-3_Employee_Policies.md\n",
      "✅ 파싱 완료 | 5-1-4_UP_Partner_Growth_Policies.md\n",
      "✅ 파싱 완료 | 5-1_Social.md\n",
      "✅ 파싱 완료 | 5-2-1_Environmental_Management_Philosophy_and_Strategies.md\n",
      "✅ 파싱 완료 | 5-2_Environmental.md\n",
      "✅ 파싱 완료 | 5-3-1_Corporate_Governance.md\n",
      "✅ 파싱 완료 | 5-3-2_Ethical_Management_and_UNGC.md\n",
      "✅ 파싱 완료 | 5-3_Governance_and_Ethics.md\n",
      "✅ 파싱 완료 | 5-4-1_World_Class_Product_History.md\n",
      "✅ 파싱 완료 | 5-4-2_Major_Certifications_GMP_GAP_GRAS.md\n",
      "✅ 파싱 완료 | 5-4_Quality_and_Certifications.md\n",
      "✅ 파싱 완료 | 5_Sustainability_ESG.md\n",
      "불러온 문서 수: 153\n",
      "첫 문서 front-matter: {'title': 'M40X_마일드_클렌징_오일', 'category1': '유니베라 제품정보', 'category2': '화장품', 'category3': 'M40X_마일드_클렌징_오일 (오일, 폼)', 'category4': '', 'keywords': ['M40X_마일드_클렌징_오일', '식물성 오일', '블랙헤드 제거', '딥 클렌징', '피부 장벽 강화', '클렌징 오일']}\n",
      "✂️ 청킹 및 메타데이터 생성 시작...\n",
      "메타 포함 청크 수: 901\n",
      "예시: m40x_maildeu_keulrenjing_oil-front => {'source_doc': 'M40X_마일드_클렌징_오일.md', 'title': 'M40X_마일드_클렌징_오일', 'category1': '유니베라 제품정보', 'category2': '화장품', 'category3': 'M40X_마일드_클렌징_오일 (오일, 폼)', 'category4': '', 'keywords': 'M40X_마일드_클렌징_오일, 식물성 오일, 블랙헤드 제거, 딥 클렌징, 피부 장벽 강화, 클렌징 오일', 'kind': 'front', 'text_content': '{\"title\": \"M40X_마일드_클렌징_오일\", \"category1\": \"유니베라 제품정보\", \"category2\": \"화장품\", \"category3\": \"M40X_마일드_클렌징_오일 (오일, 폼)\", \"category4\": \"\", \"keywords\": [\"M40X_마일드_클렌징_오일\", \"식물성 오일\", \"블랙헤드 제거\", \"딥 클렌징\", \"피부 장벽 강화\", \"클렌징 오일\"]}'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "# Cell 18: 텍스트 청킹 및 메타데이터 생성 코드\n",
    "from slugify import slugify\n",
    "\n",
    "def chunk_text(text, chunk_size=1024, overlap=100):\n",
    "    chunks, start = [], 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def normalize_fm_value(v):\n",
    "    if isinstance(v, list):\n",
    "        return \", \".join(map(str, v))\n",
    "    return v\n",
    "\n",
    "def clean_id(filename):\n",
    "    \"\"\"파일명을 slugify로 정리 (Pinecone 호환)\"\"\"\n",
    "    name_without_ext = os.path.splitext(filename)[0]\n",
    "    clean_name = slugify(name_without_ext, separator='_')\n",
    "    return clean_name if clean_name else \"doc\"\n",
    "\n",
    "# 먼저 문서 파싱 실행 (docs 변수 생성)\n",
    "print(\"📄 문서 파싱 시작...\")\n",
    "docs = []\n",
    "for file_path in md_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # 통합 파싱 함수 사용\n",
    "    fm_dict, body = parse_document_unified(text, os.path.basename(file_path))\n",
    "    \n",
    "    docs.append({\n",
    "        \"id\": os.path.basename(file_path),\n",
    "        \"front_matter\": fm_dict,\n",
    "        \"body\": body\n",
    "    })\n",
    "\n",
    "print(\"불러온 문서 수:\", len(docs))\n",
    "print(\"첫 문서 front-matter:\", docs[0][\"front_matter\"])\n",
    "\n",
    "# 청킹 및 메타데이터 생성\n",
    "print(\"✂️ 청킹 및 메타데이터 생성 시작...\")\n",
    "chunked_docs_meta = []\n",
    "for doc in docs:\n",
    "    fm = {k: normalize_fm_value(v) for k, v in (doc.get(\"front_matter\") or {}).items()}\n",
    "    base_meta = {\n",
    "        \"source_doc\": doc[\"id\"],\n",
    "        \"title\": fm.get(\"title\", \"\"),\n",
    "        \"category1\": fm.get(\"category1\", \"\"),\n",
    "        \"category2\": fm.get(\"category2\", \"\"),\n",
    "        \"category3\": fm.get(\"category3\", \"\"),\n",
    "        \"category4\": fm.get(\"category4\", \"\"),\n",
    "        \"keywords\": fm.get(\"keywords\", \"\"),\n",
    "    }\n",
    "\n",
    "    # ID 정리 (한글 유지)\n",
    "    clean_doc_id = clean_id(doc[\"id\"])\n",
    "\n",
    "    # front-matter 도 하나의 레코드로\n",
    "    if doc.get(\"front_matter\"):\n",
    "        fm_json = json.dumps(doc[\"front_matter\"], ensure_ascii=False)\n",
    "        fm_text = f\"passage: {fm_json}\"\n",
    "        chunked_docs_meta.append({\n",
    "            \"id\": f\"{clean_doc_id}-front\",\n",
    "            \"text\": fm_text,\n",
    "            \"metadata\": {**base_meta, \"kind\": \"front\", \"text_content\": fm_json[:40000]}\n",
    "        })\n",
    "\n",
    "    # 본문 청크\n",
    "    for i, chunk in enumerate(chunk_text(doc[\"body\"], chunk_size=500, overlap=75)):  # 500/75 설정 적용\n",
    "        chunk_text_full = f\"passage: {chunk}\"\n",
    "        chunked_docs_meta.append({\n",
    "            \"id\": f\"{clean_doc_id}-chunk-{i}\",\n",
    "            \"text\": chunk_text_full,\n",
    "            \"metadata\": {**base_meta, \"kind\": \"chunk\", \"text_content\": chunk[:40000]}\n",
    "        })\n",
    "\n",
    "print(\"메타 포함 청크 수:\", len(chunked_docs_meta))\n",
    "print(\"예시:\", chunked_docs_meta[0][\"id\"], \"=>\", chunked_docs_meta[0][\"metadata\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913989e1",
   "metadata": {},
   "source": [
    "## Cell 19: 🚀 7. 모델 설치 및 임베딩 생성\n",
    "\n",
    "E5-base-v2 모델을 로드하고 텍스트를 벡터로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b08ea616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패키지 설치 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Cell 20: 필요한 패키지 설치\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q python-slugify rank-bm25\n",
    "print(\"패키지 설치 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5247e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 완료: intfloat/multilingual-e5-large\n",
      "디바이스: cpu\n",
      "출력 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "# Cell 21: E5 모델 로드 및 임베딩 생성\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-large\"\n",
    "device = \"cpu\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "print(f\"모델 로드 완료: {model_name}\")\n",
    "print(f\"디바이스: {device}\")\n",
    "print(f\"출력 차원: 1024\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "680d8846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 벡터 임베딩 생성 중...\n",
      "✅ 임베딩 생성 완료: 901개\n",
      "📦 벡터 레코드 준비 중...\n",
      "✅ 레코드 준비 완료: 901개\n",
      "📤 Pinecone 업로드 시작: 10개 배치\n",
      "  📦 배치 1/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 2/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 3/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 4/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 5/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 6/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 7/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 8/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 9/10: 100개 벡터 업로드 중... ✅ 완료\n",
      "  📦 배치 10/10: 1개 벡터 업로드 중... ✅ 완료\n",
      "\n",
      "🎉 업로드 완료: 901개 벡터\n",
      "📊 인덱스 통계:\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 1081}},\n",
      " 'total_vector_count': 1081,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 22: 텍스트를 벡터로 변환하고 Pinecone에 업로드\n",
    "print(\"🚀 벡터 임베딩 생성 중...\")\n",
    "texts = [d[\"text\"] for d in chunked_docs_meta]\n",
    "embs = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "print(f\"✅ 임베딩 생성 완료: {len(embs)}개\")\n",
    "\n",
    "print(\"📦 벡터 레코드 준비 중...\")\n",
    "records = []\n",
    "for i, d in enumerate(chunked_docs_meta):\n",
    "    records.append({\n",
    "        \"id\": d[\"id\"],\n",
    "        \"values\": embs[i].tolist(),\n",
    "        \"metadata\": d[\"metadata\"]\n",
    "    })\n",
    "print(f\"✅ 레코드 준비 완료: {len(records)}개\")\n",
    "\n",
    "# 배치 업로드 (100개씩)\n",
    "batch_size = 100\n",
    "total_batches = (len(records) + batch_size - 1) // batch_size\n",
    "print(f\"📤 Pinecone 업로드 시작: {total_batches}개 배치\")\n",
    "\n",
    "for s in range(0, len(records), batch_size):\n",
    "    batch_num = (s // batch_size) + 1\n",
    "    batch_records = records[s:s+batch_size]\n",
    "    \n",
    "    print(f\"  📦 배치 {batch_num}/{total_batches}: {len(batch_records)}개 벡터 업로드 중...\", end=\" \")\n",
    "    index.upsert(vectors=batch_records)\n",
    "    print(\"✅ 완료\")\n",
    "\n",
    "print(f\"\\n🎉 업로드 완료: {len(records)}개 벡터\")\n",
    "print(\"📊 인덱스 통계:\")\n",
    "print(index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421115e",
   "metadata": {},
   "source": [
    "## Cell 23: 🔍 8. 하이브리드 검색 시스템\n",
    "\n",
    "벡터 검색과 BM25 키워드 검색을 결합한 하이브리드 검색을 구현합니다.\n",
    "\n",
    "### 검색 전략\n",
    "1. **벡터 검색**: E5 임베딩 기반 의미적 유사도 검색\n",
    "2. **BM25 검색**: 키워드 기반 정확도 검색\n",
    "3. **점수 융합**: 벡터 점수(60%) + BM25 점수(40%)\n",
    "4. **재랭킹**: CrossEncoder로 최종 순위 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc1e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 이미 Cell 22에서 업로드가 완료되었습니다.\n",
      "📊 현재 인덱스 상태:\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 1082}},\n",
      " 'total_vector_count': 1082,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 24: ⚠️ 중복 업로드 방지: 이미 Cell 22에서 업로드 완료됨\n",
    "# 이 셀은 실행하지 마세요!\n",
    "\n",
    "print(\"⚠️ 이미 Cell 22에서 업로드가 완료되었습니다.\")\n",
    "print(\"📊 현재 인덱스 상태:\")\n",
    "print(index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e119f3",
   "metadata": {},
   "source": [
    "## Cell 25: 🔍 8.1 BM25 검색 구현\n",
    "\n",
    "키워드 기반 검색을 위한 BM25 인덱스를 구축합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b91bea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone 전용 하이브리드 검색 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# Cell 26: Pinecone 기반 하이브리드 검색 (BM25는 Pinecone 후보에만 적용)\n",
    "import re, numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# 토크나이저\n",
    "def simple_tokenize(s: str):\n",
    "    return re.findall(r\"[A-Za-z0-9가-힣]+\", (s or \"\").lower())\n",
    "\n",
    "# 벡터 검색: Pinecone에서 후보 생성 (메타데이터 포함)\n",
    "def vector_search(query: str, top_k: int = 50, meta_filter=None):\n",
    "    q_vec = model.encode([f\"query: {query}\"], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "    kwargs = {\"vector\": q_vec.tolist(), \"top_k\": top_k, \"include_values\": False, \"include_metadata\": True}\n",
    "    if meta_filter:\n",
    "        kwargs[\"filter\"] = meta_filter\n",
    "    res = index.query(**kwargs)\n",
    "    # 반환: (id, vec_score, metadata)\n",
    "    return [(m[\"id\"], float(m[\"score\"]), m.get(\"metadata\", {})) for m in res.get(\"matches\", [])]\n",
    "\n",
    "# BM25 재점수화: Pinecone 후보 텍스트에 대해서만 적용\n",
    "def bm25_over_candidates(query: str, candidates):\n",
    "    # candidates: [(id, vec_score, metadata), ...]\n",
    "    docs = []\n",
    "    ids = []\n",
    "    for cid, _, meta in candidates:\n",
    "        text = (meta or {}).get(\"text_content\") or \"\"\n",
    "        if not text:\n",
    "            # 텍스트가 없으면 제목/키워드 등으로 대체\n",
    "            title = (meta or {}).get(\"title\") or \"\"\n",
    "            keywords = (meta or {}).get(\"keywords\") or \"\"\n",
    "            text = f\"{title}\\n{keywords}\"\n",
    "        ids.append(cid)\n",
    "        docs.append(simple_tokenize(text))\n",
    "    if not docs:\n",
    "        return {}\n",
    "    bm25 = BM25Okapi(docs)\n",
    "    q_tokens = simple_tokenize(query)\n",
    "    scores = bm25.get_scores(q_tokens) if q_tokens else np.zeros(len(ids))\n",
    "    # 정규화 (최댓값 기준)\n",
    "    max_b = float(np.max(scores)) if len(scores) else 0.0\n",
    "    norm = [float(s) / max_b if max_b > 0 else 0.0 for s in scores]\n",
    "    return {ids[i]: norm[i] for i in range(len(ids))}\n",
    "\n",
    "# 하이브리드: vec 후보(top_k_vec) 생성 후 BM25로 재점수화, 가중합으로 최종 정렬\n",
    "def hybrid_candidates(query: str, top_k_vec: int = 50, meta_filter=None, vec_weight: float = 0.7, bm25_weight: float = 0.3):\n",
    "    vec_cands = vector_search(query, top_k=top_k_vec, meta_filter=meta_filter)\n",
    "    if not vec_cands:\n",
    "        return []\n",
    "    bm25_scores = bm25_over_candidates(query, vec_cands)\n",
    "    merged = []\n",
    "    for cid, vscore, _meta in vec_cands:\n",
    "        bscore = bm25_scores.get(cid, 0.0)\n",
    "        final = vec_weight * float(vscore) + bm25_weight * float(bscore)\n",
    "        merged.append((cid, final))\n",
    "    merged.sort(key=lambda x: x[1], reverse=True)\n",
    "    return merged\n",
    "\n",
    "print(\"✅ Pinecone 전용 하이브리드 검색 준비 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d708f1d",
   "metadata": {},
   "source": [
    "## Cell 28: 🔍 8.2 검색 시스템\n",
    "\n",
    "하이브리드 검색으로 관련 문서를 찾습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c18a9a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pinecone 전용 검색 시스템 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# Cell 29: 검색 시스템 코드 (Pinecone 전용)\n",
    "# 로컬 백업 제거, 항상 Pinecone에서만 조회\n",
    "\n",
    "def get_text_from_pinecone(doc_id):\n",
    "    \"\"\"Pinecone에서 텍스트 내용 조회\"\"\"\n",
    "    try:\n",
    "        result = index.fetch(ids=[doc_id])\n",
    "        if doc_id in result.vectors:\n",
    "            metadata = result.vectors[doc_id].metadata or {}\n",
    "            return metadata.get(\"text_content\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "def get_meta_from_pinecone(doc_id):\n",
    "    \"\"\"Pinecone에서 메타데이터 조회\"\"\"\n",
    "    try:\n",
    "        result = index.fetch(ids=[doc_id])\n",
    "        if doc_id in result.vectors:\n",
    "            return result.vectors[doc_id].metadata or {}\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {}\n",
    "\n",
    "# 단순 래퍼 (백업 없음)\n",
    "class PineconeDict:\n",
    "    def __init__(self, fetch_func):\n",
    "        self.fetch_func = fetch_func\n",
    "    \n",
    "    def get(self, key, default=\"\"):\n",
    "        return self.fetch_func(key) or default\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        result = self.fetch_func(key)\n",
    "        return result or \"\"\n",
    "\n",
    "id2text = PineconeDict(get_text_from_pinecone)\n",
    "id2meta = PineconeDict(get_meta_from_pinecone)\n",
    "\n",
    "print(\"✅ Pinecone 전용 검색 시스템 준비 완료\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e638a",
   "metadata": {},
   "source": [
    "## Cell 30: 🤖 9. 답변 생성 시스템\n",
    "\n",
    "OpenAI GPT-4o-mini를 사용하여 컨텍스트 기반 답변을 생성합니다.\n",
    "\n",
    "### 답변 생성 과정\n",
    "1. **검색**: 하이브리드 검색으로 관련 문서 검색\n",
    "2. **재랭킹**: CrossEncoder로 상위 5개 문서 선별\n",
    "3. **컨텍스트 구성**: 선별된 문서들을 연결하여 컨텍스트 생성\n",
    "4. **답변 생성**: GPT-4o-mini로 최종 답변 생성\n",
    "5. **출처 표기**: 참고한 문서들을 bullet로 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bbeeb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 기반 RAG 챗봇 모드입니다. (exit로 종료)\n",
      "\n",
      "처리 중...⏳\n",
      "==========================================================================================\n",
      "[질문] 진세노 어쩌고 들은 제품 이썽?\n",
      "[의도] normal\n",
      "[재작성] 진세노 관련 제품이 있나요?\n",
      "[키워드] ['진세노', '제품', '관련']\n",
      "------------------------------------------------------------------------------------------\n",
      "[Vector Top]\n",
      "   1. 0.8195 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-2 | 흑삼기력프리미엄.md\n",
      "   2. 0.8043 | 흑삼기력 프리미엄 | doc-chunk-1 | 흑삼기력프리미엄.md\n",
      "   3. 0.8007 | 흑삼기력 프리미엄 | doc-chunk-0 | 흑삼기력프리미엄.md\n",
      "   4. 0.8000 | 알로엔 디오리진 수딩스틱 | alroen_diorijin_sudingseutig-chunk-1 | 알로엔_디오리진_수딩스틱.md\n",
      "   5. 0.7989 | 알로엔 디오리진 스킨케어 100 | alroen_diorijin_seukinkeeo100-chunk-1 | 알로엔_디오리진_스킨케어100.md\n",
      "   6. 0.7986 | 흑삼기력 데일리 | heugsamgiryeogdeilri-chunk-2 | 흑삼기력데일리.md\n",
      "   7. 0.7951 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-0 | 흑삼기력프리미엄.md\n",
      "   8. 0.7936 | 수면:온 | sumyeonon-chunk-7 | 수면온.md\n",
      "   9. 0.7932 | 수면:온 | sumyeonon-chunk-8 | 수면온.md\n",
      "  10. 0.7931 | 흑삼기력 데일리 | heugsamgiryeogdeilri-chunk-4 | 흑삼기력데일리.md\n",
      "------------------------------------------------------------------------------------------\n",
      "[BM25 Top (over vector candidates)]\n",
      "   1. 1.0000 | 알로엔 디오리진 SOS 크림 | alroen_diorijin_soskeurim-chunk-6 | 알로엔_디오리진_SOS크림.md\n",
      "   2. 0.9914 | 알로엔 디오리진 SOS 크림 | alroen_diorijin_soskeurim-chunk-1 | 알로엔_디오리진_SOS크림.md\n",
      "   3. 0.7317 | 슈퍼겔맥스 | syupeogelmaegseu-chunk-0 | 슈퍼겔맥스.md\n",
      "   4. 0.7188 | 리제니케어A | rijenikeeoa-chunk-0 | 리제니케어A.md\n",
      "   5. 0.7126 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-0 | 흑삼기력프리미엄.md\n",
      "   6. 0.7034 | 유니베라 유산균 플러스 | yusangyunpeulreoseu-chunk-5 | 유산균플러스.md\n",
      "   7. 0.6974 | 흑삼기력 데일리 | heugsamgiryeogdeilri-chunk-4 | 흑삼기력데일리.md\n",
      "   8. 0.0000 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-2 | 흑삼기력프리미엄.md\n",
      "   9. 0.0000 | 흑삼기력 프리미엄 | doc-chunk-1 | 흑삼기력프리미엄.md\n",
      "  10. 0.0000 | 흑삼기력 프리미엄 | doc-chunk-0 | 흑삼기력프리미엄.md\n",
      "------------------------------------------------------------------------------------------\n",
      "[Merged Top]\n",
      "   1. 0.8492 | 알로엔 디오리진 SOS 크림 | alroen_diorijin_soskeurim-chunk-6 | 알로엔_디오리진_SOS크림.md\n",
      "   2. 0.8478 | 알로엔 디오리진 SOS 크림 | alroen_diorijin_soskeurim-chunk-1 | 알로엔_디오리진_SOS크림.md\n",
      "   3. 0.7707 | 슈퍼겔맥스 | syupeogelmaegseu-chunk-0 | 슈퍼겔맥스.md\n",
      "   4. 0.7703 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-0 | 흑삼기력프리미엄.md\n",
      "   5. 0.7644 | 흑삼기력 데일리 | heugsamgiryeogdeilri-chunk-4 | 흑삼기력데일리.md\n",
      "   6. 0.7637 | 리제니케어A | rijenikeeoa-chunk-0 | 리제니케어A.md\n",
      "   7. 0.7604 | 유니베라 유산균 플러스 | yusangyunpeulreoseu-chunk-5 | 유산균플러스.md\n",
      "   8. 0.5736 | 흑삼기력 프리미엄 | heugsamgiryeogpeurimieom-chunk-2 | 흑삼기력프리미엄.md\n",
      "   9. 0.5630 | 흑삼기력 프리미엄 | doc-chunk-1 | 흑삼기력프리미엄.md\n",
      "  10. 0.5605 | 흑삼기력 프리미엄 | doc-chunk-0 | 흑삼기력프리미엄.md\n",
      "------------------------------------------------------------------------------------------\n",
      "[컨텍스트 길이] 2641\n",
      "==========================================================================================\n",
      "\n",
      "💬 답변:\n",
      "유니베라의 제품 중 \"흑삼기력 프리미엄\"과 \"흑삼기력 데일리\"가 진세노사이드를 포함한 제품입니다. 이 제품들은 기력 보충과 관련된 기능성을 가지고 있으며, 진세노사이드의 흡수율을 높이기 위한 특허 공법을 적용하고 있습니다. \n",
      "\n",
      "출처: [자료 4], [자료 5]\n",
      "\n",
      "출처:\n",
      "- 알로엔 디오리진 SOS 크림 (alroen_diorijin_soskeurim-chunk-6)\n",
      "- 알로엔 디오리진 SOS 크림 (alroen_diorijin_soskeurim-chunk-1)\n",
      "- 슈퍼겔맥스 (syupeogelmaegseu-chunk-0)\n",
      "- 흑삼기력 프리미엄 (heugsamgiryeogpeurimieom-chunk-0)\n",
      "- 흑삼기력 데일리 (heugsamgiryeogdeilri-chunk-4)\n",
      "👋 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "# Cell 32: LLM 구동 RAG 챗봇 (Pinecone 전용, 하드코딩 없음)\n",
    "import time\n",
    "from collections import deque\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "    _openai_client = OpenAI()\n",
    "except Exception as _e:\n",
    "    _openai_client = None\n",
    "\n",
    "# 전제: Cell 26의 vector_search, bm25_over_candidates 가 이미 정의되어 있어야 함\n",
    "\n",
    "# 동적 어휘/엔티티 수집 (Pinecone 메타데이터 기반)\n",
    "def collect_vocab_entities(sample_k: int = 200) -> Tuple[List[str], List[str]]:\n",
    "    try:\n",
    "        res = index.query(vector=[0.0]*1024, top_k=sample_k, include_values=False, include_metadata=True)\n",
    "    except Exception:\n",
    "        return [], []\n",
    "    vocab, entities = set(), set()\n",
    "    for m in res.get(\"matches\", []):\n",
    "        md = m.get(\"metadata\", {}) or {}\n",
    "        title = (md.get(\"title\") or \"\").strip()\n",
    "        if title:\n",
    "            vocab.add(title)\n",
    "            entities.add(title)\n",
    "        kws = md.get(\"keywords\")\n",
    "        if isinstance(kws, str):\n",
    "            for k in kws.split(','):\n",
    "                if k.strip():\n",
    "                    vocab.add(k.strip())\n",
    "        elif isinstance(kws, list):\n",
    "            for k in kws:\n",
    "                s = str(k).strip()\n",
    "                if s:\n",
    "                    vocab.add(s)\n",
    "    return sorted(vocab), sorted(entities)\n",
    "\n",
    "# LLM 유틸: JSON만 반환을 강제하는 간단 헬퍼\n",
    "def llm_json(prompt: str, max_tokens: int = 300) -> Dict:\n",
    "    if not _openai_client:\n",
    "        return {}\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"항상 유효한 JSON만 출력하세요. 설명/문장 금지.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    r = _openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.2,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    import json\n",
    "    txt = r.choices[0].message.content\n",
    "    try:\n",
    "        return json.loads(txt)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# 의도 분류 (normal / count / followup) - 규칙 없이 LLM 판단\n",
    "def classify_intent_llm(question: str, history: List[Tuple[str,str,str]]) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    다음 한국어 질문의 의도를 분류하세요. 가능한 라벨: [\"normal\",\"count\",\"followup\"].\n",
    "    - normal: 일반 정보 질의\n",
    "    - count: 개수를 묻거나 총합 등 집계 질문\n",
    "    - followup: 직전/이전 발화를 지시어/대명사로 참조하는 질문\n",
    "\n",
    "    질문: \"{question}\"\n",
    "    최근 대화(최대 3턴): {history}\n",
    "\n",
    "    JSON으로만 출력:\n",
    "    {{\"intent\":\"normal|count|followup\"}}\n",
    "    \"\"\"\n",
    "    return llm_json(prompt, max_tokens=120).get(\"intent\", \"normal\")\n",
    "\n",
    "# 질의 재작성 + 키워드 확장 + 대명사 해소 (LLM)\n",
    "def rewrite_and_expand_llm(question: str, history: List[Tuple[str,str,str]], vocab: List[str], entities: List[str]) -> Tuple[str, List[str]]:\n",
    "    prompt = f\"\"\"\n",
    "    역할: 질의 전처리기\n",
    "    입력:\n",
    "      - 질문: \"{question}\"\n",
    "      - 최근 대화(최대 3턴): {history}\n",
    "      - 동적 엔티티 후보(제품/제목): {entities[:100]}\n",
    "      - 동적 어휘(키워드): {vocab[:200]}\n",
    "    작업:\n",
    "      1) 지시어/대명사를 해소하여 구체적인 질문으로 재작성(rewritten).\n",
    "      2) 검색 키워드 3개 이내 생성(keywords): 쉼표로 구분된 명사 중심.\n",
    "    출력(JSON):\n",
    "      {{\"rewritten\":\"...\", \"keywords\":[\"k1\",\"k2\",\"k3\"]}}\n",
    "    \"\"\"\n",
    "    out = llm_json(prompt, max_tokens=260)\n",
    "    rewritten = (out.get(\"rewritten\") or question).strip()\n",
    "    kws = [k for k in (out.get(\"keywords\") or []) if k]\n",
    "    return rewritten, kws[:3]\n",
    "\n",
    "# 컨텍스트 빌드\n",
    "def build_context(merged: List[Tuple[str,float,Dict]], *, max_chars: int = 3000, top_n: int = 5) -> str:\n",
    "    parts, used = [], 0\n",
    "    for i, (cid, score, meta) in enumerate(merged[:top_n], 1):\n",
    "        title = (meta or {}).get(\"title\", \"N/A\")\n",
    "        text = (meta or {}).get(\"text_content\", \"\") or \"\"\n",
    "        if not text:\n",
    "            continue\n",
    "        remain = max_chars - used\n",
    "        if remain <= 0:\n",
    "            break\n",
    "        snippet = text[:max(0, remain-50)] + (\"...\" if len(text) > remain else \"\")\n",
    "        parts.append(f\"[자료 {i}] 제목: {title}\\n내용: {snippet}\\n\")\n",
    "        used += len(parts[-1])\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# LLM 답변 생성\n",
    "def generate_answer_llm(question: str, context: str, citations: List[Tuple[str,float,Dict]], aggregate: Dict | None, *, temperature: float = 0.2, max_tokens: int = 500) -> str:\n",
    "    if not _openai_client or not context.strip():\n",
    "        return \"관련 컨텍스트를 찾지 못했습니다.\"\n",
    "    system = \"유니베라 문서 컨텍스트에만 기반해 간결하게 답변하세요. 추측/환각 금지. 한국어 사용. 하단에 출처 표기.\"\n",
    "    user = f\"참고자료:\\n{context}\\n\\n질문: {question}\"\n",
    "    r = _openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    ans = r.choices[0].message.content\n",
    "    cites = []\n",
    "    for cid, _, meta in citations[:5]:\n",
    "        cites.append(f\"- {(meta or {}).get('title','N/A')} ({cid})\")\n",
    "    if aggregate:\n",
    "        ans = f\"{ans}\\n\\n집계결과: {aggregate['count']}개 (기준: {aggregate['basis']})\"\n",
    "    return f\"{ans}\\n\\n출처:\\n\" + \"\\n\".join(cites)\n",
    "\n",
    "# 세션 메모리 (최근 3턴)\n",
    "_history: List[Tuple[str,str,str]] = []  # (question, answer, main_entity)\n",
    "_history_deque = deque(maxlen=3)\n",
    "\n",
    "# 메인 질의 처리 (한 턴)\n",
    "def chat_once(question: str, *, vec_w: float = 0.7, bm25_w: float = 0.3, top_k: int = 50, ctx_n: int = 5, max_ctx_chars: int = 3000, debug: bool = True) -> str:\n",
    "    if debug:\n",
    "        print(\"=\"*90)\n",
    "        print(f\"[질문] {question}\")\n",
    "    vocab, entities = collect_vocab_entities(sample_k=200)\n",
    "    intent = classify_intent_llm(question, list(_history_deque))\n",
    "    rewritten, kws = rewrite_and_expand_llm(question, list(_history_deque), vocab, entities)\n",
    "    if debug:\n",
    "        print(f\"[의도] {intent}\")\n",
    "        print(f\"[재작성] {rewritten}\")\n",
    "        print(f\"[키워드] {kws}\")\n",
    "\n",
    "    # 벡터 후보 및 BM25 후보 스코어 계산 (디버그 노출용)\n",
    "    vec_cands = vector_search(rewritten, top_k=top_k)\n",
    "    bm25_scores = bm25_over_candidates(rewritten, vec_cands)\n",
    "\n",
    "    # 상위 노출용 정렬\n",
    "    vec_top = sorted(vec_cands, key=lambda x: x[1], reverse=True)[:10]\n",
    "    bm25_top = sorted([(cid, bm25_scores.get(cid, 0.0), meta) for (cid, _v, meta) in vec_cands], key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    if debug:\n",
    "        print(\"-\"*90)\n",
    "        print(\"[Vector Top]\")\n",
    "        for i, (cid, vscore, meta) in enumerate(vec_top, 1):\n",
    "            t = (meta or {}).get('title','N/A')\n",
    "            s = (meta or {}).get('source_doc','')\n",
    "            print(f\"  {i:>2}. {vscore:.4f} | {t} | {cid} | {s}\")\n",
    "        print(\"-\"*90)\n",
    "        print(\"[BM25 Top (over vector candidates)]\")\n",
    "        for i, (cid, bscore, meta) in enumerate(bm25_top, 1):\n",
    "            t = (meta or {}).get('title','N/A')\n",
    "            s = (meta or {}).get('source_doc','')\n",
    "            print(f\"  {i:>2}. {bscore:.4f} | {t} | {cid} | {s}\")\n",
    "\n",
    "    # 하이브리드 병합\n",
    "    merged = []\n",
    "    for cid, vscore, meta in vec_cands:\n",
    "        b = bm25_scores.get(cid, 0.0)\n",
    "        final = vec_w*float(vscore) + bm25_w*float(b)\n",
    "        merged.append((cid, final, meta))\n",
    "    merged.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if not merged:\n",
    "        return \"관련 정보를 찾지 못했습니다.\"\n",
    "\n",
    "    if debug:\n",
    "        print(\"-\"*90)\n",
    "        print(\"[Merged Top]\")\n",
    "        for i, (cid, fscore, meta) in enumerate(merged[:10], 1):\n",
    "            t = (meta or {}).get('title','N/A')\n",
    "            s = (meta or {}).get('source_doc','')\n",
    "            print(f\"  {i:>2}. {fscore:.4f} | {t} | {cid} | {s}\")\n",
    "\n",
    "    aggregate = maybe_aggregate_count(intent, merged, question)\n",
    "    context = build_context(merged, max_chars=max_ctx_chars, top_n=ctx_n)\n",
    "\n",
    "    if debug:\n",
    "        print(\"-\"*90)\n",
    "        print(f\"[컨텍스트 길이] {len(context)}\")\n",
    "        print(\"=\"*90)\n",
    "\n",
    "    answer = generate_answer_llm(question, context, merged, aggregate)\n",
    "\n",
    "    # 메인 엔티티 추출(LLM)에 위임하여 히스토리 저장\n",
    "    main_ent = \"\"\n",
    "    try:\n",
    "        ent_json = llm_json(f\"질문에서 핵심 제품/엔티티 1개를 추출해 JSON만 출력하세요: {{\\\"entity\\\":\\\"...\\\"}}\\n질문: {rewritten}\", max_tokens=60)\n",
    "        main_ent = (ent_json.get(\"entity\") or \"\").strip()\n",
    "    except Exception:\n",
    "        main_ent = \"\"\n",
    "    _history_deque.append((question, answer, main_ent))\n",
    "    return answer\n",
    "\n",
    "print(\"LLM 기반 RAG 챗봇 모드입니다. (exit로 종료)\")\n",
    "while True:\n",
    "    try:\n",
    "        q = input(\"\\n❓ 질문: \").strip()\n",
    "        if q.lower() in [\"exit\",\"quit\",\"종료\"]:\n",
    "            print(\"👋 종료합니다.\")\n",
    "            break\n",
    "        if not q:\n",
    "            continue\n",
    "        print(\"\\n처리 중...⏳\")\n",
    "        out = chat_once(q, vec_w=0.7, bm25_w=0.3, top_k=50, ctx_n=5, max_ctx_chars=3000, debug=True)\n",
    "        print(\"\\n💬 답변:\\n\" + out)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n👋 종료합니다.\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
